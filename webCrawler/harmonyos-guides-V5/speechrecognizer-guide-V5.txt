语音识别
将一段中文音频信息（中文、中文语境下的英文；短语音模式不超过60s，长语音模式不超过8h）转换为文本，音频信息可以为pcm音频文件或者实时语音。
场景介绍
手机/平板等设备在无网状态下，为听障人士或不方便收听音频场景提供音频转文本能力。
约束与限制
该能力当前不支持模拟器。
开发步骤
 在使用语音识别时，将实现语音识别相关的类添加至工程。import { speechRecognizer } from '@kit.CoreSpeechKit';\nimport { BusinessError } from '@kit.BasicServicesKit';  调用createEngine方法，对引擎进行初始化，并创建SpeechRecognitionEngine实例。createEngine方法提供了两种调用形式，当前以其中一种作为示例，其他方式可参考API参考。 let asrEngine: speechRecognizer.SpeechRecognitionEngine;\nlet sessionId: string = '123456';\n// 创建引擎，通过callback形式返回\n// 设置创建引擎参数\nlet extraParam: Record<string, Object> = {\"locate\": \"CN\", \"recognizerMode\": \"short\"};\nlet initParamsInfo: speechRecognizer.CreateEngineParams = {\n  language: 'zh-CN',\n  online: 1,\n  extraParams: extraParam\n};\n// 调用createEngine方法\nspeechRecognizer.createEngine(initParamsInfo, (err: BusinessError, speechRecognitionEngine: speechRecognizer.SpeechRecognitionEngine) => {\n  if (!err) {\n    console.info('Succeeded in creating engine.');\n    // 接收创建引擎的实例\n    asrEngine = speechRecognitionEngine;\n  } else {\n    console.error(`Failed to create engine. Code: ${err.code}, message: ${err.message}.`);\n  }\n});  得到SpeechRecognitionEngine实例对象后，实例化RecognitionListener对象，调用setListener方法设置回调，用来接收语音识别相关的回调信息。// 创建回调对象\nlet setListener: speechRecognizer.RecognitionListener = {\n  // 开始识别成功回调\n  onStart(sessionId: string, eventMessage: string) {\n    console.info(`onStart, sessionId: ${sessionId} eventMessage: ${eventMessage}`);\n  },\n  // 事件回调\n  onEvent(sessionId: string, eventCode: number, eventMessage: string) {\n    console.info(`onEvent, sessionId: ${sessionId} eventCode: ${eventCode} eventMessage: ${eventMessage}`);\n  },\n  // 识别结果回调，包括中间结果和最终结果\n  onResult(sessionId: string, result: speechRecognizer.SpeechRecognitionResult) {\n    console.info(`onResult, sessionId: ${sessionId} sessionId: ${JSON.stringify(result)}`);\n  },\n  // 识别完成回调\n  onComplete(sessionId: string, eventMessage: string) {\n    console.info(`onComplete, sessionId: ${sessionId} eventMessage: ${eventMessage}`);\n  },\n  // 错误回调，错误码通过本方法返回\n  // 如：返回错误码1002200006，识别引擎正忙，引擎正在识别中\n  // 更多错误码请参考错误码参考\n  onError(sessionId: string, errorCode: number, errorMessage: string) {\n    console.error(`onError, sessionId: ${sessionId} errorCode: ${errorCode} errorMessage: ${errorMessage}`);\n  }\n}\n// 设置回调\nasrEngine.setListener(setListener);  分别为音频文件转文字和麦克风转文字功能设置开始识别的相关参数，调用startListening方法，开始合成。// 开始识别\nprivate startListeningForWriteAudio() {\n  // 设置开始识别的相关参数\n  let recognizerParams: speechRecognizer.StartParams = {\n    sessionId: this.sessionId,\n    audioInfo: { audioType: 'pcm', sampleRate: 16000, soundChannel: 1, sampleBit: 16 } //audioInfo参数配置请参考AudioInfo\n  }\n  // 调用开始识别方法\n  asrEngine.startListening(recognizerParams);\n};\n\nprivate startListeningForRecording() {\n  let audioParam: speechRecognizer.AudioInfo = { audioType: 'pcm', sampleRate: 16000, soundChannel: 1, sampleBit: 16 }\n  let extraParam: Record<string, Object> = {\n    \"recognitionMode\": 0,\n    \"vadBegin\": 2000,\n    \"vadEnd\": 3000,\n    \"maxAudioDuration\": 20000\n  }\n  let recognizerParams: speechRecognizer.StartParams = {\n    sessionId: this.sessionId,\n    audioInfo: audioParam,\n    extraParams: extraParam\n  }\n  console.info('startListening start');\n  asrEngine.startListening(recognizerParams);\n};  传入音频流，调用writeAudio方法，开始写入音频流。读取音频文件时，开发者需预先准备一个pcm格式音频文件。let uint8Array: Uint8Array = new Uint8Array();\n// 可以通过如下方式获取音频流：1、通过录音获取音频流；2、从音频文件中读取音频流\n// 2、从音频文件中读取音频流:demo参考\n// 写入音频流，音频流长度仅支持640或1280\nasrEngine.writeAudio(sessionId, uint8Array);  （可选）当需要查询语音识别服务支持的语种信息，可调用listLanguages方法。         listLanguages方法提供了两种调用形式，当前以其中一种作为示例，其他方式可参考API参考。        // 设置查询相关的参数\nlet languageQuery: speechRecognizer.LanguageQuery = {\n  sessionId: sessionId\n};\n// 调用listLanguages方法\nasrEngine.listLanguages(languageQuery).then((res: Array<string>) => {\n  console.info(`Succeeded in listing languages, result: ${JSON.stringify(res)}.`);\n}).catch((err: BusinessError) => {\n  console.error(`Failed to list languages. Code: ${err.code}, message: ${err.message}.`);\n});   （可选）当需要结束识别时，可调用finish方法。// 结束识别\nasrEngine.finish(sessionId);  （可选）当需要取消识别时，可调用cancel方法。// 取消识别\nasrEngine.cancel(sessionId);  （可选）当需要释放语音识别引擎资源时，可调用shutdown方法。// 释放识别引擎资源\nasrEngine.shutdown();  需要在module.json5配置文件中添加ohos.permission.MICROPHONE权限，确保麦克风使用正常。详细步骤可查看声明权限章节。//...\n\"requestPermissions\": [\n  {\n    \"name\" : \"ohos.permission.MICROPHONE\",\n    \"reason\": \"$string:reason\",\n    \"usedScene\": {\n      \"abilities\": [\n        \"EntryAbility\"\n      ],\n      \"when\":\"inuse\"\n    }\n  }\n],\n//...  
开发实例
import { speechRecognizer } from '@kit.CoreSpeechKit';\nimport { BusinessError } from '@kit.BasicServicesKit';\nimport { fileIo } from '@kit.CoreFileKit';\nimport { hilog } from '@kit.PerformanceAnalysisKit';\nimport AudioCapturer from './AudioCapturer';\n\nconst TAG = 'CoreSpeechKitDemo';\n\nlet asrEngine: speechRecognizer.SpeechRecognitionEngine;\n\n@Entry\n@Component\nstruct Index {\n  @State createCount: number = 0;\n  @State result: boolean = false;\n  @State voiceInfo: string = \"\";\n  @State sessionId: string = \"123456\";\n  private mAudioCapturer = new AudioCapturer();\n\n  build() {\n    Column() {\n      Scroll() {\n        Column() {\n          Button() {\n            Text(\"CreateEngineByCallback\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AE7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            this.createCount++;\n            hilog.info(0x0000, TAG, `CreateAsrEngine：createCount:${this.createCount}`);\n            this.createByCallback();\n          })\n\n          Button() {\n            Text(\"setListener\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AE7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            this.setListener();\n          })\n\n          Button() {\n            Text(\"startRecording\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AE7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            this.startRecording();\n          })\n\n          Button() {\n            Text(\"writeAudio\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AE7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            this.writeAudio();\n          })\n\n          Button() {\n            Text(\"queryLanguagesCallback\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AE7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            this.queryLanguagesCallback();\n          })\n\n          Button() {\n            Text(\"finish\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AE7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            // 结束识别\n            hilog.info(0x0000, TAG, \"finish click:-->\");\n            asrEngine.finish(this.sessionId);\n          })\n\n          Button() {\n            Text(\"cancel\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AE7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            // 取消识别\n            hilog.info(0x0000, TAG, \"cancel click:-->\");\n            asrEngine.cancel(this.sessionId);\n          })\n\n          Button() {\n            Text(\"shutdown\")\n              .fontColor(Color.White)\n              .fontSize(20)\n          }\n          .type(ButtonType.Capsule)\n          .backgroundColor(\"#0x317AA7\")\n          .width(\"80%\")\n          .height(50)\n          .margin(10)\n          .onClick(() => {\n            // 释放引擎\n            asrEngine.shutdown();\n          })\n        }\n        .layoutWeight(1)\n      }\n      .width('100%')\n      .height('100%')\n\n    }\n  }\n\n  // 创建引擎，通过callback形式返回\n  private createByCallback() {\n    // 设置创建引擎参数\n    let extraParam: Record<string, Object> = {\"locate\": \"CN\", \"recognizerMode\": \"short\"};\n    let initParamsInfo: speechRecognizer.CreateEngineParams = {\n      language: 'zh-CN',\n      online: 1,\n      extraParams: extraParam\n    };\n\n    // 调用createEngine方法\n    speechRecognizer.createEngine(initParamsInfo, (err: BusinessError, speechRecognitionEngine:\n      speechRecognizer.SpeechRecognitionEngine) => {\n      if (!err) {\n        hilog.info(0x0000, TAG, 'Succeeded in creating engine.');\n        // 接收创建引擎的实例\n        asrEngine = speechRecognitionEngine;\n      } else {\n        // 无法创建引擎时返回错误码1002200001，原因：语种不支持、模式不支持、初始化超时、资源不存在等导致创建引擎失败\n        // 无法创建引擎时返回错误码1002200006，原因：引擎正在忙碌中，一般多个应用同时调用语音识别引擎时触发\n        // 无法创建引擎时返回错误码1002200008，原因：引擎已被销毁\n        hilog.error(0x0000, TAG, `Failed to create engine. Code: ${err.code}, message: ${err.message}.`);\n      }\n    });\n  }\n\n  // 查询语种信息，以callback形式返回\n  private queryLanguagesCallback() {\n    // 设置查询相关参数\n    let languageQuery: speechRecognizer.LanguageQuery = {\n      sessionId: '123456'\n    };\n    // 调用listLanguages方法\n    asrEngine.listLanguages(languageQuery, (err: BusinessError, languages: Array<string>) => {\n      if (!err) {\n        // 接收目前支持的语种信息\n        hilog.info(0x0000, TAG, `Succeeded in listing languages, result: ${JSON.stringify(languages)}`);\n      } else {\n        hilog.error(0x0000, TAG, `Failed to create engine. Code: ${err.code}, message: ${err.message}.`);\n      }\n    });\n  };\n\n  // 开始识别\n  private startListeningForWriteAudio() {\n    // 设置开始识别的相关参数\n    let recognizerParams: speechRecognizer.StartParams = {\n      sessionId: this.sessionId,\n      audioInfo: { audioType: 'pcm', sampleRate: 16000, soundChannel: 1, sampleBit: 16 } //audioInfo参数配置请参考AudioInfo\n    }\n    // 调用开始识别方法\n    asrEngine.startListening(recognizerParams);\n  };\n\n  private startListeningForRecording() {\n    let audioParam: speechRecognizer.AudioInfo = { audioType: 'pcm', sampleRate: 16000, soundChannel: 1, sampleBit: 16 }\n    let extraParam: Record<string, Object> = {\n      \"recognitionMode\": 0,\n      \"vadBegin\": 2000,\n      \"vadEnd\": 3000,\n      \"maxAudioDuration\": 20000\n    }\n    let recognizerParams: speechRecognizer.StartParams = {\n      sessionId: this.sessionId,\n      audioInfo: audioParam,\n      extraParams: extraParam\n    }\n    hilog.info(0x0000, TAG, 'startListening start');\n    asrEngine.startListening(recognizerParams);\n  };\n\n\n  // 写音频流\n  private async writeAudio() {\n    this.startListeningForWriteAudio();\n    hilog.error(0x0000, TAG, `Failed to read from file. Code`);\n    let ctx = getContext(this);\n    let filenames: string[] = fileIo.listFileSync(ctx.filesDir);\n    if (filenames.length <= 0) {\n      hilog.error(0x0000, TAG, `Failed to read from file. Code`);\n      return;\n    }\n    hilog.error(0x0000, TAG, `Failed to read from file. Code`);\n    let filePath: string = `${ctx.filesDir}/${filenames[0]}`;\n    let file = fileIo.openSync(filePath, fileIo.OpenMode.READ_WRITE);\n    try {\n      let buf: ArrayBuffer = new ArrayBuffer(1280);\n      let offset: number = 0;\n      while (1280 == fileIo.readSync(file.fd, buf, {\n        offset: offset\n      })) {\n        let uint8Array: Uint8Array = new Uint8Array(buf);\n        asrEngine.writeAudio(\"123456\", uint8Array);\n        await this.countDownLatch(1);\n        offset = offset + 1280;\n      }\n    } catch (err) {\n      hilog.error(0x0000, TAG, `Failed to read from file. Code: ${err.code}, message: ${err.message}.`);\n    } finally {\n      if (null != file) {\n        fileIo.closeSync(file);\n      }\n    }\n  }\n\n  // 麦克风语音转文本\n  private async startRecording() {\n    this.startListeningForRecording();\n    // 录音获取音频\n    let data: ArrayBuffer;\n    hilog.info(0x0000, TAG, 'create capture success');\n    this.mAudioCapturer.init((dataBuffer: ArrayBuffer) => {\n      hilog.info(0x0000, TAG, 'start write');\n      hilog.info(0x0000, TAG, 'ArrayBuffer ' + JSON.stringify(dataBuffer));\n      data = dataBuffer\n      let uint8Array: Uint8Array = new Uint8Array(data);\n      hilog.info(0x0000, TAG, 'ArrayBuffer uint8Array ' + JSON.stringify(uint8Array));\n      // 写入音频流\n      asrEngine.writeAudio(\"1234567\", uint8Array);\n    });\n  };\n  // 计时\n  public async countDownLatch(count: number) {\n    while (count > 0) {\n      await this.sleep(40);\n      count--;\n    }\n  }\n  // 睡眠\n  private sleep(ms: number):Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  // 设置回调\n  private setListener() {\n    // 创建回调对象\n    let setListener: speechRecognizer.RecognitionListener = {\n      // 开始识别成功回调\n      onStart(sessionId: string, eventMessage: string) {\n        hilog.info(0x0000, TAG, `onStart, sessionId: ${sessionId} eventMessage: ${eventMessage}`);\n      },\n      // 事件回调\n      onEvent(sessionId: string, eventCode: number, eventMessage: string) {\n        hilog.info(0x0000, TAG, `onEvent, sessionId: ${sessionId} eventCode: ${eventCode} eventMessage: ${eventMessage}`);\n      },\n      // 识别结果回调，包括中间结果和最终结果\n      onResult(sessionId: string, result: speechRecognizer.SpeechRecognitionResult) {\n        hilog.info(0x0000, TAG, `onResult, sessionId: ${sessionId} sessionId: ${JSON.stringify(result)}`);\n      },\n      // 识别完成回调\n      onComplete(sessionId: string, eventMessage: string) {\n        hilog.info(0x0000, TAG, `onComplete, sessionId: ${sessionId} eventMessage: ${eventMessage}`);\n      },\n      // 错误回调，错误码通过本方法返回\n      // 返回错误码1002200002，开始识别失败，重复启动startListening方法时触发\n      // 更多错误码请参考错误码参考\n      onError(sessionId: string, errorCode: number, errorMessage: string) {\n        hilog.error(0x0000, TAG, `onError, sessionId: ${sessionId} errorCode: ${errorCode} errorMessage: ${errorMessage}`);\n      },\n    }\n    // 设置回调\n    asrEngine.setListener(setListener);\n  };\n}
添加AudioCapturer.ts文件用于获取麦克风音频流。
'use strict';\n/*\n * Copyright (c) Huawei Technologies Co., Ltd. 2023-2023. All rights reserved.\n */\n\nimport {audio} from '@kit.AudioKit';\nimport { hilog } from '@kit.PerformanceAnalysisKit';\n\nconst TAG = 'AudioCapturer';\n\n/**\n * Audio collector tool\n */\nexport default class AudioCapturer {\n  /**\n   * Collector object\n   */\n  private mAudioCapturer = null;\n\n  /**\n   * Audio Data Callback Method\n   */\n  private mDataCallBack: (data: ArrayBuffer) => void = null;\n\n  /**\n   * Indicates whether recording data can be obtained.\n   */\n  private mCanWrite: boolean = true;\n\n  /**\n   * Audio stream information\n   */\n  private audioStreamInfo = {\n    samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_16000,\n    channels: audio.AudioChannel.CHANNEL_1,\n    sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE,\n    encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW\n  }\n\n  /**\n   * Audio collector information\n   */\n  private audioCapturerInfo = {\n    source: audio.SourceType.SOURCE_TYPE_MIC,\n    capturerFlags: 0\n  }\n\n  /**\n   * Audio Collector Option Information\n   */\n  private audioCapturerOptions = {\n    streamInfo: this.audioStreamInfo,\n    capturerInfo: this.audioCapturerInfo\n  }\n\n  /**\n   *  Initialize\n   * @param audioListener\n   */\n  public async init(dataCallBack: (data: ArrayBuffer) => void) {\n    if (null != this.mAudioCapturer) {\n      hilog.error(0x0000, TAG, 'AudioCapturerUtil already init');\n      return;\n    }\n    this.mDataCallBack = dataCallBack;\n    this.mAudioCapturer = await audio.createAudioCapturer(this.audioCapturerOptions).catch(error => {\n      hilog.error(0x0000, TAG, `AudioCapturerUtil init createAudioCapturer failed, code is ${error.code}, message is ${error.message}`);\n    });\n  }\n\n  /**\n   * start recording\n   */\n  public async start() {\n    hilog.error(0x0000, TAG, `AudioCapturerUtil start`);\n    let stateGroup = [audio.AudioState.STATE_PREPARED, audio.AudioState.STATE_PAUSED, audio.AudioState.STATE_STOPPED];\n    if (stateGroup.indexOf(this.mAudioCapturer.state) === -1) {\n      hilog.error(0x0000, TAG, `AudioCapturerUtil start failed`);\n      return;\n    }\n    this.mCanWrite = true;\n    await this.mAudioCapturer.start();\n    while (this.mCanWrite) {\n      let bufferSize = await this.mAudioCapturer.getBufferSize();\n      let buffer = await this.mAudioCapturer.read(bufferSize, true);\n      this.mDataCallBack(buffer)\n    }\n  }\n\n  /**\n   * stop recording\n   */\n  public async stop() {\n    if (this.mAudioCapturer.state !== audio.AudioState.STATE_RUNNING && this.mAudioCapturer.state !== audio.AudioState.STATE_PAUSED) {\n      hilog.error(0x0000, TAG, `AudioCapturerUtil stop Capturer is not running or paused`);\n      return;\n    }\n    this.mCanWrite = false;\n    await this.mAudioCapturer.stop();\n    if (this.mAudioCapturer.state === audio.AudioState.STATE_STOPPED) {\n      hilog.info(0x0000, TAG, `AudioCapturerUtil Capturer stopped`);\n    } else {\n      hilog.error(0x0000, TAG, `Capturer stop failed`);\n    }\n  }\n\n  /**\n   * release\n   */\n  public async release() {\n    if (this.mAudioCapturer.state === audio.AudioState.STATE_RELEASED || this.mAudioCapturer.state === audio.AudioState.STATE_NEW) {\n      hilog.error(0x0000, TAG, `Capturer already released`);\n      return;\n    }\n    await this.mAudioCapturer.release();\n    this.mAudioCapturer = null;\n    if (this.mAudioCapturer.state == audio.AudioState.STATE_RELEASED) {\n      hilog.info(0x0000, TAG, `Capturer released`);\n    } else {\n      hilog.error(0x0000, TAG, `Capturer release failed`);\n    }\n  }\n}
在EntryAbility.ets文件中添加麦克风权限。
import { abilityAccessCtrl, AbilityConstant, UIAbility, Want } from '@kit.AbilityKit';\nimport { hilog } from '@kit.PerformanceAnalysisKit';\nimport { window } from '@kit.ArkUI';\nimport { BusinessError } from '@kit.BasicServicesKit';\n\nexport default class EntryAbility extends UIAbility {\n  onCreate(want: Want, launchParam: AbilityConstant.LaunchParam): void {\n    hilog.info(0x0000, 'testTag', '%{public}s', 'Ability onCreate');\n  }\n\n  onDestroy(): void {\n    hilog.info(0x0000, 'testTag', '%{public}s', 'Ability onDestroy');\n  }\n\n  onWindowStageCreate(windowStage: window.WindowStage): void {\n    // Main window is created, set main page for this ability\n    hilog.info(0x0000, 'testTag', '%{public}s', 'Ability onWindowStageCreate');\n\n    let atManager = abilityAccessCtrl.createAtManager();\n    atManager.requestPermissionsFromUser(this.context, ['ohos.permission.MICROPHONE']).then((data) => {\n      hilog.info(0x0000, 'testTag', 'data:' + JSON.stringify(data));\n      hilog.info(0x0000, 'testTag', 'data permissions:' + data.permissions);\n      hilog.info(0x0000, 'testTag', 'data authResults:' + data.authResults);\n    }).catch((err: BusinessError) => {\n      hilog.error(0x0000, 'testTag', 'errCode: ' + err.code + 'errMessage: ' + err.message);\n    });\n\n    windowStage.loadContent('pages/Index', (err, data) => {\n      if (err.code) {\n        hilog.error(0x0000, 'testTag', 'Failed to load the content. Cause: %{public}s', JSON.stringify(err) ?? '');\n        return;\n      }\n      hilog.info(0x0000, 'testTag', 'Succeeded in loading the content. Data: %{public}s', JSON.stringify(data) ?? '');\n    });\n  }\n\n  onWindowStageDestroy(): void {\n    // Main window is destroyed, release UI related resources\n    hilog.info(0x0000, 'testTag', '%{public}s', 'Ability onWindowStageDestroy');\n  }\n\n  onForeground(): void {\n    // Ability has brought to foreground\n    hilog.info(0x0000, 'testTag', '%{public}s', 'Ability onForeground');\n  }\n\n  onBackground(): void {\n    // Ability has back to background\n    hilog.info(0x0000, 'testTag', '%{public}s', 'Ability onBackground');\n  }\n}
