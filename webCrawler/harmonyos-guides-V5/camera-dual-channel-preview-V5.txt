双路预览(ArkTS)
在开发相机应用时，需要先参考开发准备申请相关权限。
双路预览，即应用可同时使用两路预览流，一路用于在屏幕上显示，一路用于图像处理等其他操作，提升处理效率。
相机应用通过控制相机，实现图像显示（预览）、照片保存（拍照）、视频录制（录像）等基础操作。相机开发模型为Surface模型，即应用通过Surface进行数据传递，通过ImageReceiver的surface获取拍照流的数据、通过XComponent的surface获取预览流的数据。
如果要实现双路预览，即将拍照流改为预览流，将拍照流中的surface改为预览流的surface，通过ImageReceiver的surface创建previewOutput，其余流程与拍照流和预览流一致。
详细的API说明请参考Camera API参考。
约束与限制
 暂不支持动态添加流，即不能在没有调用session.stop的情况下，调用addOutput添加流。 对ImageReceiver组件获取到的图像数据处理后，需要将对应的图像Buffer释放，确保Surface的BufferQueue正常轮转。 
调用流程
双路方案调用流程图建议如下：
开发步骤
 用于处理图像的第一路预览流：创建ImageReceiver对象，获取SurfaceId创建第一路预览流，注册图像监听，按需处理预览流每帧图像。 用于显示画面的第二路预览流：创建XComponent组件，获取SurfaceId创建第二路预览流，预览流画面直接在组件内渲染。 创建预览流获取数据：创建上述两路预览流，配置进相机会话，启动会话后，两路预览流同时获取数据。 
[h2]用于处理图像的第一路预览流
 获取第一路预览流SurfaceId：创建ImageReceiver对象，通过ImageReceiver对象可获取其SurfaceId。 import { image } from '@kit.ImageKit';\nimageWidth: number = 1920; // 请使用设备支持profile的size的宽\nimageHeight: number = 1080; // 请使用设备支持profile的size的高\n\nasync function initImageReceiver():Promise<void>{\n  // 创建ImageReceiver对象\n  let size: image.Size = { width: this.imageWidth, height: this.imageHeight };\n  let imageReceiver = image.createImageReceiver(size, image.ImageFormat.JPEG, 8);\n  // 获取取第一路流SurfaceId\n  let imageReceiverSurfaceId = await imageReceiver.getReceivingSurfaceId();\n  console.info(`initImageReceiver imageReceiverSurfaceId:${imageReceiverSurfaceId}`);\n} 注册监听处理预览流每帧图像数据：通过ImageReceiver组件中imageArrival事件监听获取底层返回的图像数据，详细的API说明请参考Image API参考。 import { BusinessError } from '@kit.BasicServicesKit';\nimport { image } from '@kit.ImageKit';\n\nfunction onImageArrival(receiver: image.ImageReceiver): void {\n  // 注册imageArrival监听\n  receiver.on('imageArrival', () => {\n    // 获取图像\n    receiver.readNextImage((err: BusinessError, nextImage: image.Image) => {\n      if (err || nextImage === undefined) {\n        console.error('readNextImage failed');\n        return;\n      }\n      // 解析图像内容\n      nextImage.getComponent(image.ComponentType.JPEG, async (err: BusinessError, imgComponent: image.Component) => {\n        if (err || imgComponent === undefined) {\n          console.error('getComponent failed');\n        }\n        if (imgComponent.byteBuffer) {\n          // 详情见下方解析图片buffer数据参考，本示例以方式一为例\n          let width = nextImage.size.width; // 获取图片的宽\n          let height = nextImage.size.height; // 获取图片的高\n          let stride = imgComponent.rowStride; // 获取图片的stride\n          console.debug(`getComponent with width:${width} height:${height} stride:${stride}`);\n          // stride与width一致\n          if (stride == width) {\n            let pixelMap = await image.createPixelMap(imgComponent.byteBuffer, {\n              size: { height: height, width: width },\n              srcPixelFormat: 8,\n            })\n          } else {\n            // stride与width不一致\n            const dstBufferSize = width * height * 1.5\n            const dstArr = new Uint8Array(dstBufferSize)\n            for (let j = 0; j < height * 1.5; j++) {\n              const srcBuf = new Uint8Array(imgComponent.byteBuffer, j * stride, width)\n              dstArr.set(srcBuf, j * width)\n            }\n            let pixelMap = await image.createPixelMap(dstArr.buffer, {\n              size: { height: height, width: width },\n              srcPixelFormat: 8,\n            })\n          }\n        } else {\n          console.error('byteBuffer is null');\n        }\n        // 确保当前buffer没有在使用的情况下，可进行资源释放\n        // 如果对buffer进行异步操作，需要在异步操作结束后再释放该资源（nextImage.release()）\n        nextImage.release();\n      })\n    })\n  })\n} 通过 image.Component 解析图片buffer数据参考：     需要确认图像的宽width是否与行距rowStride一致，如果不一致可参考以下方式处理：   方式一：去除imgComponent.byteBuffer中stride数据，拷贝得到新的buffer，调用不支持stride的接口处理buffer。 // 以NV21为例（YUV_420_SP格式的图片）YUV_420_SP内存计算公式：长x宽+(长x宽)/2\nconst dstBufferSize = width * height * 1.5;\nconst dstArr = new Uint8Array(dstBufferSize);\n// 逐行读取buffer数据\nfor (let j = 0; j < height * 1.5; j++) {\n  // imgComponent.byteBuffer的每行数据拷贝前width个字节到dstArr中\n  const srcBuf = new Uint8Array(imgComponent.byteBuffer, j * stride, width);\n  dstArr.set(srcBuf, j * width);\n}\nlet pixelMap = await image.createPixelMap(dstArr.buffer, {\n  size: { height: height, width: width }, srcPixelFormat: 8\n}); 方式二：根据stride*height创建pixelMap，然后调用pixelMap的cropSync方法裁剪掉多余的像素。 // 创建pixelMap，width宽传行距stride的值\nlet pixelMap = await image.createPixelMap(imgComponent.byteBuffer, {\n  size:{height: height, width: stride}, srcPixelFormat: 8});\n// 裁剪多余的像素\npixelMap.cropSync({size:{width:width, height:height}, x:0, y:0}); 方式三：将原始imgComponent.byteBuffer和stride信息一起传给支持stride的接口处理。 
[h2]用于显示画面的第二路预览流
获取第二路预览流SurfaceId：创建XComponent组件用于预览流显示，获取surfaceId请参考XComponent组件提供的getXcomponentSurfaceId方法，而XComponent的能力由UI提供，相关介绍可参考XComponent组件参考。
@Component\nstruct example {\n  xComponentCtl: XComponentController = new XComponentController();\n  surfaceId:string = '';\n  imageWidth: number = 1920;\n  imageHeight: number = 1080;\n\n  build() {\n    XComponent({\n      id: 'componentId',\n      type: 'surface',\n      controller: this.xComponentCtl\n    })\n      .onLoad(async () => {\n        console.info('onLoad is called');\n        this.surfaceId = this.xComponentCtl.getXComponentSurfaceId(); // 获取组件surfaceId\n        // 使用surfaceId创建预览流，开启相机，组件实时渲染每帧预览流数据\n      })\n      .width(px2vp(this.imageHeight))\n      .height(px2vp(this.imageWidth))\n  }\n}
[h2]创建预览流获取数据
通过两个SurfaceId分别创建两路预览流输出，加入相机会话，启动相机会话，获取预览流数据。
function createDualPreviewOutput(cameraManager: camera.CameraManager, previewProfile: camera.Profile,\nsession: camera.Session,\nimageReceiverSurfaceId: string, xComponentSurfaceId: string): void {\n    // 使用imageReceiverSurfaceId创建第一路预览\n    let previewOutput1 = cameraManager.createPreviewOutput(previewProfile, imageReceiverSurfaceId);\n    if (!previewOutput1) {\n    console.error('createPreviewOutput1 error');\n    }\n    // 使用xComponentSurfaceId创建第二路预览\n    let previewOutput2 = cameraManager.createPreviewOutput(previewProfile, xComponentSurfaceId);\n    if (!previewOutput2) {\n    console.error('createPreviewOutput2 error');\n    }\n    // 添加第一路预览流输出\n    session.addOutput(previewOutput1);\n    // 添加第二路预览流输出\n    session.addOutput(previewOutput2);\n}
完整示例
import { camera } from '@kit.CameraKit';\nimport { image } from '@kit.ImageKit';\nimport { BusinessError } from '@kit.BasicServicesKit';\n\n@Entry\n@Component\nstruct Index {\n  private imageReceiver: image.ImageReceiver | undefined = undefined;\n  private imageReceiverSurfaceId: string = '';\n  private xComponentCtl: XComponentController = new XComponentController();\n  private xComponentSurfaceId: string = '';\n  @State imageWidth: number = 1920;\n  @State imageHeight: number = 1080;\n  private cameraManager: camera.CameraManager | undefined = undefined;\n  private cameras: Array<camera.CameraDevice> | Array<camera.CameraDevice> = [];\n  private cameraInput: camera.CameraInput | undefined = undefined;\n  private previewOutput1: camera.PreviewOutput | undefined = undefined;\n  private previewOutput2: camera.PreviewOutput | undefined = undefined;\n  private session: camera.VideoSession | undefined = undefined;\n\n  onPageShow(): void {\n    console.info('onPageShow');\n    this.initImageReceiver();\n    if (this.xComponentSurfaceId !== '') {\n      this.initCamera();\n    }\n  }\n\n  onPageHide(): void {\n    console.info('onPageHide');\n    this.releaseCamera();\n  }\n\n  /**\n   * 获取ImageReceiver的SurfaceId\n   * @param receiver\n   * @returns\n   */\n  async initImageReceiver(): Promise<void> {\n    if (!this.imageReceiver) {\n      // 创建ImageReceiver\n      let size: image.Size = { width: this.imageWidth, height: this.imageHeight };\n      this.imageReceiver = image.createImageReceiver(size, image.ImageFormat.JPEG, 8);\n      // 获取取第一路流SurfaceId\n      this.imageReceiverSurfaceId = await this.imageReceiver.getReceivingSurfaceId();\n      console.info(`initImageReceiver imageReceiverSurfaceId:${this.imageReceiverSurfaceId}`);\n      // 注册监听处理预览流每帧图像数据\n      this.onImageArrival(this.imageReceiver);\n    }\n  }\n\n  /**\n   * 注册ImageReceiver图像监听\n   * @param receiver\n   */\n  onImageArrival(receiver: image.ImageReceiver): void {\n    // 注册imageArrival监听\n    receiver.on('imageArrival', () => {\n      console.info('image arrival');\n      // 获取图像\n      receiver.readNextImage((err: BusinessError, nextImage: image.Image) => {\n        if (err || nextImage === undefined) {\n          console.error('readNextImage failed');\n          return;\n        }\n        // 解析图像内容\n        nextImage.getComponent(image.ComponentType.JPEG, async (err: BusinessError, imgComponent: image.Component) => {\n          if (err || imgComponent === undefined) {\n            console.error('getComponent failed');\n          }\n          if (imgComponent.byteBuffer) {\n            // 请参考步骤7解析buffer数据，本示例以方式一为例\n            let width = nextImage.size.width; // 获取图片的宽\n            let height = nextImage.size.height; // 获取图片的高\n            let stride = imgComponent.rowStride; // 获取图片的stride\n            console.debug(`getComponent with width:${width} height:${height} stride:${stride}`);\n            // stride与width一致\n            if (stride == width) {\n              let pixelMap = await image.createPixelMap(imgComponent.byteBuffer, {\n                size: { height: height, width: width },\n                srcPixelFormat: 8,\n              })\n            } else {\n              // stride与width不一致\n              const dstBufferSize = width * height * 1.5 // 以NV21为例（YUV_420_SP格式的图片）YUV_420_SP内存计算公式：长x宽+(长x宽)/2\n              const dstArr = new Uint8Array(dstBufferSize)\n              for (let j = 0; j < height * 1.5; j++) {\n                const srcBuf = new Uint8Array(imgComponent.byteBuffer, j * stride, width)\n                dstArr.set(srcBuf, j * width)\n              }\n              let pixelMap = await image.createPixelMap(dstArr.buffer, {\n                size: { height: height, width: width },\n                srcPixelFormat: 8,\n              })\n            }\n          } else {\n            console.error('byteBuffer is null');\n          }\n          // 确保当前buffer没有在使用的情况下，可进行资源释放\n          // 如果对buffer进行异步操作，需要在异步操作结束后再释放该资源（nextImage.release()）\n          nextImage.release();\n          console.info('image process done');\n        })\n      })\n    })\n  }\n\n  build() {\n    Column() {\n      XComponent({\n        id: 'componentId',\n        type: 'surface',\n        controller: this.xComponentCtl\n      })\n        .onLoad(async () => {\n          console.info('onLoad is called');\n          this.xComponentSurfaceId = this.xComponentCtl.getXComponentSurfaceId(); // 获取组件surfaceId\n          // 初始化相机，组件实时渲染每帧预览流数据\n          this.initCamera()\n        })\n        .width(px2vp(this.imageHeight))\n        .height(px2vp(this.imageWidth))\n    }.justifyContent(FlexAlign.Center)\n    .height('100%')\n    .width('100%')\n  }\n\n  // 初始化相机\n  async initCamera(): Promise<void> {\n    console.info(`initCamera imageReceiverSurfaceId:${this.imageReceiverSurfaceId} xComponentSurfaceId:${this.xComponentSurfaceId}`);\n    try {\n      // 获取相机管理器实例\n      this.cameraManager = camera.getCameraManager(getContext(this));\n      if (!this.cameraManager) {\n        console.error('initCamera getCameraManager');\n      }\n      // 获取当前设备支持的相机device列表\n      this.cameras = this.cameraManager.getSupportedCameras();\n      if (!this.cameras) {\n        console.error('initCamera getSupportedCameras');\n      }\n      // 选择一个相机device，创建cameraInput输出对象\n      this.cameraInput = this.cameraManager.createCameraInput(this.cameras[0]);\n      if (!this.cameraInput) {\n        console.error('initCamera createCameraInput');\n      }\n      // 打开相机\n      await this.cameraInput.open().catch((err: BusinessError) => {\n        console.error(`initCamera open fail: ${JSON.stringify(err)}`);\n      })\n      // 获取相机device支持的profile\n      let capability: camera.CameraOutputCapability =\n        this.cameraManager.getSupportedOutputCapability(this.cameras[0], camera.SceneMode.NORMAL_VIDEO);\n      if (!capability) {\n        console.error('initCamera getSupportedOutputCapability');\n      }\n      // 根据业务需求选择一个支持的预览流profile\n      let previewProfile: camera.Profile = capability.previewProfiles[0];\n      this.imageWidth = previewProfile.size.width; // 更新xComponent组件的宽\n      this.imageHeight = previewProfile.size.height; // 更新xComponent组件的高\n      console.info(`initCamera imageWidth:${this.imageWidth} imageHeight:${this.imageHeight}`);\n      // 使用imageReceiverSurfaceId创建第一路预览\n      this.previewOutput1 = this.cameraManager.createPreviewOutput(previewProfile, this.imageReceiverSurfaceId);\n      if (!this.previewOutput1) {\n        console.error('initCamera createPreviewOutput1');\n      }\n      // 使用xComponentSurfaceId创建第二路预览\n      this.previewOutput2 = this.cameraManager.createPreviewOutput(previewProfile, this.xComponentSurfaceId);\n      if (!this.previewOutput2) {\n        console.error('initCamera createPreviewOutput2');\n      }\n      // 创建录像模式相机会话\n      this.session = this.cameraManager.createSession(camera.SceneMode.NORMAL_VIDEO) as camera.VideoSession;\n      if (!this.session) {\n        console.error('initCamera createSession');\n      }\n      // 开始配置会话\n      this.session.beginConfig();\n      // 添加相机设备输入\n      this.session.addInput(this.cameraInput);\n      // 添加第一路预览流输出\n      this.session.addOutput(this.previewOutput1);\n      // 添加第二路预览流输出\n      this.session.addOutput(this.previewOutput2);\n      // 提交会话配置\n      await this.session.commitConfig();\n      // 开始启动已配置的输入输出流\n      await this.session.start();\n    } catch (error) {\n      console.error(`initCamera fail: ${JSON.stringify(error)}`);\n    }\n  }\n\n  // 释放相机\n  async releaseCamera(): Promise<void> {\n    console.info('releaseCamera E');\n    try {\n      // 停止当前会话\n      await this.session?.stop();\n      // 释放相机输入流\n      await this.cameraInput?.close();\n      // 释放预览输出流\n      await this.previewOutput1?.release();\n      // 释放拍照输出流\n      await this.previewOutput2?.release();\n      // 释放会话\n      await this.session?.release();\n    } catch (error) {\n      console.error(`initCamera fail: ${JSON.stringify(error)}`);\n    }\n  }\n}
