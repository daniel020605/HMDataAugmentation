开发音频通话功能
在音频通话场景下，音频输出（播放对端声音）和音频输入（录制本端声音）会同时进行，应用可以通过使用AudioRenderer来实现音频输出，通过使用AudioCapturer来实现音频输入，同时使用AudioRenderer和AudioCapturer即可实现音频通话功能。
在音频通话开始和结束时，应用可以自行检查当前的音频场景模式和铃声模式，以便采取合适的音频管理及提示策略。
以下代码示范了同时使用AudioRenderer和AudioCapturer实现音频通话功能的基本过程，其中未包含音频通话数据的传输过程，实际开发中，需要将网络传输来的对端通话数据解码播放，此处仅以读取音频文件的数据代替；同时需要将本端录制的通话数据编码打包，通过网络发送给对端，此处仅以将数据写入音频文件代替。
使用AudioRenderer播放对端的通话声音
该过程与使用AudioRenderer开发音频播放功能过程相似，关键区别在于audioRendererInfo参数和音频数据来源。audioRendererInfo参数中，音频内容类型需设置为语音：CONTENT_TYPE_SPEECH，音频流使用类型需设置为VOIP通话：STREAM_USAGE_VOICE_COMMUNICATION。
import { audio } from '@kit.AudioKit';\nimport { fileIo as fs } from '@kit.CoreFileKit';\nimport { BusinessError } from '@kit.BasicServicesKit';\n\nconst TAG = 'VoiceCallDemoForAudioRenderer';\n// 与使用AudioRenderer开发音频播放功能过程相似，关键区别在于audioRendererInfo参数和音频数据来源\nclass Options {\n  offset?: number;\n  length?: number;\n}\n\nlet bufferSize: number = 0;\nlet renderModel: audio.AudioRenderer | undefined = undefined;\nlet audioStreamInfo: audio.AudioStreamInfo = {\n  samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_48000, // 采样率\n  channels: audio.AudioChannel.CHANNEL_2, // 通道\n  sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE, // 采样格式\n  encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW // 编码格式\n};\nlet audioRendererInfo: audio.AudioRendererInfo = {\n  // 需使用通话场景相应的参数\n  usage: audio.StreamUsage.STREAM_USAGE_VOICE_COMMUNICATION, // 音频流使用类型：VOIP通话\n  rendererFlags: 0 // 音频渲染器标志：默认为0即可\n};\nlet audioRendererOptions: audio.AudioRendererOptions = {\n  streamInfo: audioStreamInfo,\n  rendererInfo: audioRendererInfo\n};\nlet path = getContext().cacheDir;\n// 确保该沙箱路径下存在该资源\nlet filePath = path + '/StarWars10s-2C-48000-4SW.wav';\nlet file: fs.File = fs.openSync(filePath, fs.OpenMode.READ_ONLY);\nlet writeDataCallback = (buffer: ArrayBuffer) => {\n  let options: Options = {\n    offset: bufferSize,\n    length: buffer.byteLength\n  };\n  fs.readSync(file.fd, buffer, options);\n  bufferSize += buffer.byteLength;\n};\n\n// 初始化，创建实例，设置监听事件\naudio.createAudioRenderer(audioRendererOptions, (err: BusinessError, renderer: audio.AudioRenderer) => { // 创建AudioRenderer实例\n  if (!err) {\n    console.info(`${TAG}: creating AudioRenderer success`);\n    renderModel = renderer;\n    if (renderModel !== undefined) {\n      renderModel.on('stateChange', (state: audio.AudioState) => { // 设置监听事件，当转换到指定的状态时触发回调\n        if (state == 1) {\n          console.info('audio renderer state is: STATE_PREPARED');\n        }\n        if (state == 2) {\n          console.info('audio renderer state is: STATE_RUNNING');\n        }\n      });\n      renderModel.on('markReach', 1000, (position: number) => { // 订阅markReach事件，当渲染的帧数达到1000帧时触发回调\n        if (position == 1000) {\n          console.info('ON Triggered successfully');\n        }\n      });\n      renderModel.on('writeData', writeDataCallback);\n    }\n  } else {\n    console.info(`${TAG}: creating AudioRenderer failed, error: ${err.message}`);\n  }\n});\n\n// 开始一次音频渲染\nasync function start() {\n  if (renderModel !== undefined) {\n    let stateGroup: number[] = [audio.AudioState.STATE_PREPARED, audio.AudioState.STATE_PAUSED, audio.AudioState.STATE_STOPPED];\n    if (stateGroup.indexOf(renderModel.state.valueOf()) === -1) { // 当且仅当状态为STATE_PREPARED、STATE_PAUSED和STATE_STOPPED之一时才能启动渲染\n      console.error(TAG + 'start failed');\n      return;\n    }\n    renderModel.start((err: BusinessError) => {\n      if (err) {\n        console.error('Renderer start failed.');\n      } else {\n        console.info('Renderer start success.');\n      }\n    });\n  }\n}\n\n// 暂停渲染\nasync function pause() {\n  if (renderModel !== undefined) {\n    // 只有渲染器状态为STATE_RUNNING的时候才能暂停\n    if (renderModel.state.valueOf() !== audio.AudioState.STATE_RUNNING) {\n      console.info('Renderer is not running');\n      return;\n    }\n    await renderModel.pause(); // 暂停渲染\n    if (renderModel.state.valueOf() === audio.AudioState.STATE_PAUSED) {\n      console.info('Renderer is paused.');\n    } else {\n      console.error('Pausing renderer failed.');\n    }\n  }\n}\n\n// 停止渲染\nasync function stop() {\n  if (renderModel !== undefined) {\n    // 只有渲染器状态为STATE_RUNNING或STATE_PAUSED的时候才可以停止\n    if (renderModel.state.valueOf() !== audio.AudioState.STATE_RUNNING && renderModel.state.valueOf() !== audio.AudioState.STATE_PAUSED) {\n      console.info('Renderer is not running or paused.');\n      return;\n    }\n    await renderModel.stop(); // 停止渲染\n    if (renderModel.state.valueOf() === audio.AudioState.STATE_STOPPED) {\n      console.info('Renderer stopped.');\n    } else {\n      console.error('Stopping renderer failed.');\n    }\n  }\n}\n\n// 销毁实例，释放资源\nasync function release() {\n  if (renderModel !== undefined) {\n    // 渲染器状态不是STATE_RELEASED状态，才能release\n    if (renderModel.state.valueOf() === audio.AudioState.STATE_RELEASED) {\n      console.info('Renderer already released');\n      return;\n    }\n    await renderModel.release(); // 释放资源\n    if (renderModel.state.valueOf() === audio.AudioState.STATE_RELEASED) {\n      console.info('Renderer released');\n    } else {\n      console.error('Renderer release failed.');\n    }\n  }\n}
使用AudioCapturer录制本端的通话声音
该过程与使用AudioCapturer开发音频录制功能过程相似，关键区别在于audioCapturerInfo参数和音频数据流向。audioCapturerInfo参数中音源类型需设置为语音通话：SOURCE_TYPE_VOICE_COMMUNICATION。
所有录制均需要申请麦克风权限：ohos.permission.MICROPHONE，申请方式请参考向用户申请授权。
import { audio } from '@kit.AudioKit';\nimport { fileIo as fs } from '@kit.CoreFileKit';\nimport { BusinessError } from '@kit.BasicServicesKit';\n\nconst TAG = 'VoiceCallDemoForAudioCapturer';\nclass Options {\n  offset?: number;\n  length?: number;\n}\n\n// 与使用AudioCapturer开发音频录制功能过程相似，关键区别在于audioCapturerInfo参数和音频数据流向\nlet bufferSize: number = 0;\nlet audioCapturer: audio.AudioCapturer | undefined = undefined;\nlet audioStreamInfo: audio.AudioStreamInfo = {\n  samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_48000, // 采样率\n  channels: audio.AudioChannel.CHANNEL_2, // 通道\n  sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE, // 采样格式\n  encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW // 编码格式\n};\nlet audioCapturerInfo: audio.AudioCapturerInfo = {\n  // 需使用通话场景相应的参数\n  source: audio.SourceType.SOURCE_TYPE_VOICE_COMMUNICATION, // 音源类型：语音通话\n  capturerFlags: 0 // 音频采集器标志：默认为0即可\n};\nlet audioCapturerOptions: audio.AudioCapturerOptions = {\n  streamInfo: audioStreamInfo,\n  capturerInfo: audioCapturerInfo\n};\nlet path = getContext().cacheDir;\nlet filePath = path + '/StarWars10s-2C-48000-4SW.wav';\nlet file: fs.File = fs.openSync(filePath, fs.OpenMode.READ_WRITE | fs.OpenMode.CREATE);\nlet readDataCallback = (buffer: ArrayBuffer) => {\n  let options: Options = {\n    offset: bufferSize,\n    length: buffer.byteLength\n  };\n  fs.writeSync(file.fd, buffer, options);\n  bufferSize += buffer.byteLength;\n};\n\n// 初始化，创建实例，设置监听事件\nasync function init() {\n  audio.createAudioCapturer(audioCapturerOptions, (err: BusinessError, capturer: audio.AudioCapturer) => { // 创建AudioCapturer实例\n    if (err) {\n      console.error(`Invoke createAudioCapturer failed, code is ${err.code}, message is ${err.message}`);\n      return;\n    }\n    console.info(`${TAG}: create AudioCapturer success`);\n    audioCapturer = capturer;\n    if (audioCapturer !== undefined) {\n      audioCapturer.on('markReach', 1000, (position: number) => { // 订阅markReach事件，当采集的帧数达到1000帧时触发回调\n        if (position === 1000) {\n          console.info('ON Triggered successfully');\n        }\n      });\n      audioCapturer.on('periodReach', 2000, (position: number) => { // 订阅periodReach事件，当采集的帧数每达到2000时触发回调\n        if (position === 2000) {\n          console.info('ON Triggered successfully');\n        }\n      });\n      audioCapturer.on('readData', readDataCallback);\n    }\n  });\n}\n\n// 开始一次音频采集\nasync function start() {\n  if (audioCapturer !== undefined) {\n    let stateGroup: number[] = [audio.AudioState.STATE_PREPARED, audio.AudioState.STATE_PAUSED, audio.AudioState.STATE_STOPPED];\n    if (stateGroup.indexOf(audioCapturer.state.valueOf()) === -1) { // 当且仅当状态为STATE_PREPARED、STATE_PAUSED和STATE_STOPPED之一时才能启动采集\n      console.error(`${TAG}: start failed`);\n      return;\n    }\n    audioCapturer.start((err: BusinessError) => {\n      if (err) {\n        console.error('Capturer start failed.');\n      } else {\n        console.info('Capturer start success.');\n      }\n    });\n  }\n}\n\n// 停止采集\nasync function stop() {\n  if (audioCapturer !== undefined) {\n    // 只有采集器状态为STATE_RUNNING或STATE_PAUSED的时候才可以停止\n    if (audioCapturer.state.valueOf() !== audio.AudioState.STATE_RUNNING && audioCapturer.state.valueOf() !== audio.AudioState.STATE_PAUSED) {\n      console.info('Capturer is not running or paused');\n      return;\n    }\n    await audioCapturer.stop(); // 停止采集\n    if (audioCapturer.state.valueOf() === audio.AudioState.STATE_STOPPED) {\n      console.info('Capturer stopped');\n    } else {\n      console.error('Capturer stop failed');\n    }\n  }\n}\n\n// 销毁实例，释放资源\nasync function release() {\n  if (audioCapturer !== undefined) {\n    // 采集器状态不是STATE_RELEASED或STATE_NEW状态，才能release\n    if (audioCapturer.state.valueOf() === audio.AudioState.STATE_RELEASED || audioCapturer.state.valueOf() === audio.AudioState.STATE_NEW) {\n      console.info('Capturer already released');\n      return;\n    }\n    await audioCapturer.release(); // 释放资源\n    if (audioCapturer.state.valueOf() === audio.AudioState.STATE_RELEASED) {\n      console.info('Capturer released');\n    } else {\n      console.error('Capturer release failed');\n    }\n  }\n}
