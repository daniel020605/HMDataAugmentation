视频解码
调用者可以调用本模块的Native API接口，完成视频解码，即将媒体数据解码成YUV文件或送显。
具体实现可参考示例工程。
当前支持的解码能力请参考AVCodec支持的格式。
如果需要对HDRVivid视频进行解码，需要配置MimeType为H265 (OH_AVCODEC_MIMETYPE_VIDEO_HEVC)，本功能从API version 11开始支持。
通过视频解码，应用可以实现以下重点能力，包括：
限制约束
 Buffer模式不支持HDRVivid解码。 Flush，Reset，Stop之后，重新Start时，需要重新传PPS/SPS。具体示例请参考Surface模式步骤14调用OH_VideoDecoder_Flush()。 Flush，Reset，Stop，Destroy在非回调线程中执行时，会等待所有回调执行完成后，将执行结果返回给用户。 由于硬件解码器资源有限，每个解码器在使用完毕后都必须调用OH_VideoDecoder_Destroy接口来销毁实例并释放资源。 视频解码输入码流仅支持AnnexB格式，且支持的AnnexB格式支持多slice，要求同一帧的多个slice一次送入解码器。 在调用Flush，Reset，Stop的过程中，调用者不应对之前回调函数获取到的OH_AVBuffer继续进行操作。 DRM解密能力在Surface模式下既支持非安全视频通路，也支持安全视频通路，在Buffer模式下仅支持非安全视频通路。 Buffer模式和Surface模式使用方式一致的接口，所以只提供了Surface模式的示例。 在Buffer模式下，调用者通过输出回调函数OH_AVCodecOnNewOutputBuffer获取到OH_AVBuffer的指针对象后，必须通过调用OH_VideoDecoder_FreeOutputBuffer接口 来通知系统该对象已被使用完毕。这样系统才能够将后续解码的数据写入到相应的位置。如果调用者在调用OH_AVBuffer_GetNativeBuffer接口时获取到OH_NativeBuffer指针对象，并且该对象的生命周期超过了当前的OH_AVBuffer指针对象，那么需要进行一次数据的拷贝操作。在这种情况下，调用者需要自行管理新生成的OH_NativeBuffer对象的生命周期，确保其正确使用和释放。 
surface输出与buffer输出
 两者数据的输出方式不同。 两者的适用场景不同：  surface输出是指用OHNativeWindow来传递输出数据，可以与其他模块对接，例如XComponent。 buffer输出是指经过解码的数据会以共享内存的方式输出。  在接口调用的过程中，两种方式的接口调用方式基本一致，但存在以下差异点：  在Surface模式下，可选择调用OH_VideoDecoder_FreeOutputBuffer接口丢弃输出帧（不送显）；在Buffer模式下，应用必须调用OH_VideoDecoder_FreeOutputBuffer接口释放数据。 Surface模式下，应用在解码器就绪前，必须调用OH_VideoDecoder_SetSurface接口设置OHNativeWindow，启动后，调用OH_VideoDecoder_RenderOutputBuffer接口将解码数据送显。 输出回调传出的buffer，在Buffer模式下，可以获取共享内存的地址和数据信息；在Surface模式下，只能获取buffer的数据信息。  
两种模式的开发步骤详细说明请参考：Surface模式和Buffer模式。
状态机调用关系
如下为状态机调用关系图：
 有两种方式可以使解码器进入Initialized状态：  初始创建解码器实例时，解码器处于Initialized状态。 任何状态下，调用OH_VideoDecoder_Reset接口，解码器将会移回Initialized状态。  Initialized状态下，调用OH_VideoDecoder_Configure接口配置解码器，配置成功后解码器进入Configured状态。 Configured状态下，调用OH_VideoDecoder_Prepare接口进入Prepared状态。 Prepared状态下，调用OH_VideoDecoder_Start接口使解码器进入Executing状态：  处于Executing状态时，调用OH_VideoDecoder_Stop接口可以使解码器返回到Prepared状态。  在极少数情况下，解码器可能会遇到错误并进入Error状态。解码器的错误传递，可以通过队列操作返回无效值或者抛出异常：  Error状态下，可以调用解码器OH_VideoDecoder_Reset接口将解码器移到Initialized状态；或者调用OH_VideoDecoder_Destroy接口移动到最后的Released状态。  Executing状态具有三个子状态：Flushed、Running和End-of-Stream：  在调用了OH_VideoDecoder_Start接口之后，解码器立即进入Running子状态。 对于处于Executing状态的解码器，可以调用OH_VideoDecoder_Flush接口返回到Flushed子状态。 当待处理数据全部传递给解码器后，在input buffers队列中为最后一个入队的input buffer中添加AVCODEC_BUFFER_FLAGS_EOS标记，遇到这个标记时，解码器会转换为End-of-Stream子状态。在此状态下，解码器不再接受新的输入，但是仍然会继续生成输出，直到输出到达尾帧。  使用完解码器后，必须调用OH_VideoDecoder_Destroy接口销毁解码器实例。使解码器进入Released状态。 
开发指导
详细的API说明请参考API文档。
如下为视频解码调用关系图：
 虚线表示可选。 实线表示必选。 
[h2]在 CMake 脚本中链接动态库
target_link_libraries(sample PUBLIC libnative_media_codecbase.so)\ntarget_link_libraries(sample PUBLIC libnative_media_core.so)\ntarget_link_libraries(sample PUBLIC libnative_media_vdec.so)
上述'sample'字样仅为示例，此处由调用者根据实际工程目录自定义。
[h2]定义基础结构
本部分示例代码按照C++17标准编写，仅作参考。开发者可以参考此部分，定义自己的buffer对象。
 添加头文件。 #include <condition_variable>\n#include <memory>\n#include <mutex>\n#include <queue>\n#include <shared_mutex> 解码器回调buffer的信息。 struct CodecBufferInfo {\n    CodecBufferInfo(uint32_t index, OH_AVBuffer *buffer): index(index), buffer(buffer), isValid(true) {}\n    // 回调buffer\n    OH_AVBuffer *buffer = nullptr;\n    // 回调buffer对应的index\n    uint32_t index = 0;\n    // 判断当前buffer信息是否有效\n    bool isValid = true;\n}; 解码输入输出队列。 class CodecBufferQueue {\npublic:\n    // 将回调buffer的信息传入队列\n    void Enqueue(const std::shared_ptr<CodecBufferInfo> bufferInfo)\n    {\n        std::unique_lock<std::mutex> lock(mutex_);\n        bufferQueue_.push(bufferInfo);\n        cond_.notify_all();\n    }\n\n    // 获取回调buffer的信息\n    std::shared_ptr<CodecBufferInfo> Dequeue(int32_t timeoutMs = 1000)\n    {\n        std::unique_lock<std::mutex> lock(mutex_);\n        (void)cond_.wait_for(lock, std::chrono::milliseconds(timeoutMs), [this]() { return !bufferQueue_.empty(); });\n        if (bufferQueue_.empty()) {\n            return nullptr;\n        }\n        std::shared_ptr<CodecBufferInfo> bufferInfo = bufferQueue_.front();\n        bufferQueue_.pop();\n        return bufferInfo;\n    }\n\n    // 清空队列，之前的回调buffer设置为不可用\n    void Flush()\n    {\n        std::unique_lock<std::mutex> lock(mutex_);\n        while (!bufferQueue_.empty()) {\n            std::shared_ptr<CodecBufferInfo> bufferInfo = bufferQueue_.front();\n            // Flush、Stop、Reset、Destroy操作之后，之前回调的buffer信息设置为无效\n            bufferInfo->isValid = false;\n            bufferQueue_.pop();\n        }\n    }\n\nprivate:\n    std::mutex mutex_;\n    std::condition_variable cond_;\n    std::queue<std::shared_ptr<CodecBufferInfo>> bufferQueue_;\n}; 全局变量 仅做参考，可以根据实际情况将其封装到对象中。 // 视频帧宽度\nint32_t width = 320;\n// 视频帧高度\nint32_t height = 240;\n// 视频像素格式\n OH_AVPixelFormat pixelFormat = AV_PIXEL_FORMAT_NV12;\n// 视频宽跨距\nint32_t widthStride = 0;\n// 视频高跨距\nint32_t heightStride = 0;\n// 解码器实例指针\nOH_AVCodec *videoDec = nullptr;\n// 解码器同步锁\nstd::shared_mutex codecMutex;\n// 解码器输入队列\nCodecBufferQueue inQueue;\n// 解码器输出队列\nCodecBufferQueue outQueue; 
[h2]Surface模式
参考以下示例代码，调用者可以完成Surface模式下视频解码的全流程。此处以H.264码流文件输入，解码送显输出为例。
本模块目前仅支持异步模式的数据轮转。
 添加头文件。 #include <multimedia/player_framework/native_avcodec_videodecoder.h>\n#include <multimedia/player_framework/native_avcapability.h>\n#include <multimedia/player_framework/native_avcodec_base.h>\n#include <multimedia/player_framework/native_avformat.h>\n#include <multimedia/player_framework/native_avbuffer.h>\n#include <fstream> 创建解码器实例对象。 调用者可以通过名称或媒体类型创建解码器。示例中的变量说明如下：  videoDec：视频解码器实例的指针。 capability：解码器能力查询实例的指针。 OH_AVCODEC_MIMETYPE_VIDEO_AVC：AVC格式视频编解码器。  // 通过codecname创建解码器，应用有特殊需求，比如选择支持某种分辨率规格的解码器，可先查询capability，再根据codec name创建解码器。\nOH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, false);\n// 创建硬件解码器实例\nOH_AVCapability *capability= OH_AVCodec_GetCapabilityByCategory(OH_AVCODEC_MIMETYPE_VIDEO_AVC, false, HARDWARE);\nconst char *name = OH_AVCapability_GetName(capability);\nOH_AVCodec *videoDec = OH_VideoDecoder_CreateByName(name); // 通过MIME TYPE创建解码器，只能创建系统推荐的特定编解码器\n// 涉及创建多路编解码器时，优先创建硬件解码器实例，硬件资源不够时再创建软件解码器实例\n// 软/硬解: 创建H264解码器\nOH_AVCodec *videoDec = OH_VideoDecoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);\n// 软/硬解: 创建H265解码器\nOH_AVCodec *videoDec = OH_VideoDecoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_HEVC); 调用OH_VideoDecoder_RegisterCallback()设置回调函数。 注册回调函数指针集合OH_AVCodecCallback，包括：  OH_AVCodecOnError 解码器运行错误，返回的错误码详情请参见：OH_AVCodecOnError； OH_AVCodecOnStreamChanged 码流信息变化，如码流宽、高变化； OH_AVCodecOnNeedInputBuffer 运行过程中需要新的输入数据，即解码器已准备好，可以输入数据； OH_AVCodecOnNewOutputBuffer 运行过程中产生了新的输出数据，即解码完成(注：Surface模式buffer参数为空)。  调用者可以通过处理该回调报告的信息，确保解码器正常运转。 回调函数的具体实现可参考示例工程。 // 解码异常回调OH_AVCodecOnError实现\nstatic void OnError(OH_AVCodec *codec, int32_t errorCode, void *userData)\n{\n    // 回调的错误码由调用者判断处理\n    (void)codec;\n    (void)errorCode;\n    (void)userData;\n}\n\n// 解码数据流变化回调OH_AVCodecOnStreamChanged实现\nstatic void OnStreamChanged(OH_AVCodec *codec, OH_AVFormat *format, void *userData)\n{\n    // 可通过format获取到变化后的视频宽、高、跨距等\n    (void)codec;\n    (void)userData;\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_PIC_WIDTH, &width);\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_PIC_HEIGHT, &height);\n}\n\n// 解码输入回调OH_AVCodecOnNeedInputBuffer实现\nstatic void OnNeedInputBuffer(OH_AVCodec *codec, uint32_t index, OH_AVBuffer *buffer, void *userData)\n{\n    // 输入帧的数据buffer和对应的index送入inQueue队列\n    (void)codec;\n    (void)userData;\n    inQueue.Enqueue(std::make_shared<CodecBufferInfo>(index, buffer));\n}\n\n// 解码输出回调OH_AVCodecOnNewOutputBuffer实现\nstatic void OnNewOutputBuffer(OH_AVCodec *codec, uint32_t index, OH_AVBuffer *buffer, void *userData)\n{\n    // 完成帧的数据buffer和对应的index送入outQueue队列\n    (void)codec;\n    (void)userData;\n    outQueue.Enqueue(std::make_shared<CodecBufferInfo>(index, buffer));\n}\n// 配置异步回调，调用 OH_VideoDecoder_RegisterCallback 接口\nOH_AVCodecCallback cb = {&OnError, &OnStreamChanged, &OnNeedInputBuffer, &OnNewOutputBuffer};\n// 配置异步回调\nint32_t ret = OH_VideoDecoder_RegisterCallback(videoDec, cb, NULL); // NULL:用户特定数据userData为空 \nif (ret != AV_ERR_OK) {\n    // 异常处理\n}      在回调函数中，对数据队列进行操作时，需要注意多线程同步的问题。 播放视频时，若视频码流的SPS中包含颜色信息，解码器会把这些信息（RangeFlag、ColorPrimary、MatrixCoefficient、TransferCharacteristic）通过 OH_AVCodecOnStreamChanged接口中的OH_AVFormat返回。 视频解码的Surface模式下，内部数据默认是走HEBC（High Efficiency Bandwidth Compression，高效带宽压缩），无法获取到widthStride和heightStride的值。    （可选）OH_VideoDecoder_SetDecryptionConfig设置解密配置。在获取到DRM信息(参考音视频解封装开发步骤第4步)，完成DRM许可证申请后，通过此接口进行解密配置。此接口需在Prepare前调用。在Surface模式下，DRM解密能力既支持安全视频通路，也支持非安全视频通路。DRM相关接口详见DRM API文档。 添加头文件。 #include <multimedia/drm_framework/native_mediakeysystem.h>\n#include <multimedia/drm_framework/native_mediakeysession.h>\n#include <multimedia/drm_framework/native_drm_err.h>\n#include <multimedia/drm_framework/native_drm_common.h> 在 CMake 脚本中链接动态库。 target_link_libraries(sample PUBLIC libnative_drm.so) 根据DRM码流要求的内容保护级别和硬件设备支持的内容保护级别创建对应的通路。 如果DRM码流要求的内容保护级别是硬件级保护，则推荐使用安全视频通路，示例如下： // 根据DRM信息创建指定的DRM系统, 以创建\"com.wiseplay.drm\"为例\nMediaKeySystem *system = nullptr;\nint32_t ret = OH_MediaKeySystem_Create(\"com.wiseplay.drm\", &system);\nif (system == nullptr) {\n    printf(\"create media key system failed\");\n    return;\n}\n\n// 创建解密会话，如果使用安全视频通路，应创建CONTENT_PROTECTION_LEVEL_HW_CRYPTO及其以上内容保护级别的MediaKeySession；\nMediaKeySession *session = nullptr;\nDRM_ContentProtectionLevel contentProtectionLevel = CONTENT_PROTECTION_LEVEL_HW_CRYPTO;\nret = OH_MediaKeySystem_CreateMediaKeySession(system, &contentProtectionLevel, &session);\nif (ret != DRM_OK) {\n    // 如创建失败，请查看DRM接口文档及日志信息\n    printf(\"create media key session failed.\");\n    return;\n}\nif (session == nullptr) {\n    printf(\"media key session is nullptr.\");\n    return;\n}\n\n// 获取许可证请求、设置许可证响应等\n\n// 设置解密配置, 即将解密会话、安全视频通路标志设置到解码器中\n// 如果DRM解决方案支持安全视频通路，在使用安全视频通路时，需将secureVideoPath设置为true，并在此之前须创建安全解码器\n// 即在步骤3使用OH_VideoDecoder_CreateByName函数、参数为解码器名称后拼接.secure（如“[CodecName].secure”）创建安全解码器\nbool secureVideoPath = true;\nret = OH_VideoDecoder_SetDecryptionConfig(videoDec, session, secureVideoPath); 如果DRM码流要求的内容保护级别是软件级保护，则推荐使用非安全视频通路，示例如下： // 根据DRM信息创建指定的DRM系统, 以创建\"com.wiseplay.drm\"为例\nMediaKeySystem *system = nullptr;\nint32_t ret = OH_MediaKeySystem_Create(\"com.wiseplay.drm\", &system);\nif (system == nullptr) {\n    printf(\"create media key system failed\");\n    return;\n}\n\n// 创建解密会话，如果使用安全视频通路，应创建CONTENT_PROTECTION_LEVEL_HW_CRYPTO及其以上内容保护级别的MediaKeySession；\n// 如果使用非安全视频通路，应创建CONTENT_PROTECTION_LEVEL_SW_CRYPTO及以上内容保护级别的MediaKeySession\nMediaKeySession *session = nullptr;\nDRM_ContentProtectionLevel contentProtectionLevel = CONTENT_PROTECTION_LEVEL_SW_CRYPTO;\nret = OH_MediaKeySystem_CreateMediaKeySession(system, &contentProtectionLevel, &session);\nif (ret != DRM_OK) {\n    // 如创建失败，请查看DRM接口文档及日志信息\n    printf(\"create media key session failed.\");\n    return;\n}\nif (session == nullptr) {\n    printf(\"media key session is nullptr.\");\n    return;\n}\n\n// 获取许可证请求、设置许可证响应等\n\n// 设置解密配置, 即将解密会话、安全视频通路标志设置到解码器中\n// 如果DRM解决方案支持安全视频通路，在使用安全视频通路时，需将secureVideoPath设置为true，并在此之前须创建安全解码器\n// 即在步骤2使用OH_VideoDecoder_CreateByName函数、参数为解码器名称后拼接.secure（如“[CodecName].secure”）创建安全解码器\nbool secureVideoPath = false;\nret = OH_VideoDecoder_SetDecryptionConfig(videoDec, session, secureVideoPath); 调用OH_VideoDecoder_Configure()配置解码器。 详细可配置选项的说明请参考视频专有键值对。 参数校验规则请参考OH_VideoDecoder_Configure() 参考文档。 参数取值范围可以通过能力查询接口获取，具体示例请参考获取支持的编解码能力。 目前支持的所有格式都必须配置以下选项：视频帧宽度、视频帧高度、视频像素格式。 OH_AVFormat *format = OH_AVFormat_Create();\n// 写入format\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_WIDTH, width); // 必须配置\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_HEIGHT, height); // 必须配置\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_PIXEL_FORMAT, pixelFormat);\n// 可选，配置低时延解码\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_VIDEO_ENABLE_LOW_LATENCY, 1);\n// 配置解码器\nint32_t ret = OH_VideoDecoder_Configure(videoDec, format);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\nOH_AVFormat_Destroy(format); 设置surface。 本例中的nativeWindow，有两种方式获取：  如果解码后直接显示，则从XComponent组件获取，获取方式请参考 XComponent； 如果解码后接OpenGL后处理，则从NativeImage获取，获取方式请参考 NativeImage。  Surface模式，调用者可以在解码过程中执行该步骤，即动态切换surface。 // 配置送显窗口参数\nint32_t ret = OH_VideoDecoder_SetSurface(videoDec, window);    // 从XComponent获取window\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} （可选）OH_VideoDecoder_SetParameter()动态配置解码器surface参数。 详细可配置选项的说明请参考视频专有键值对。 OH_AVFormat *format = OH_AVFormat_Create();\n// 配置显示旋转角度\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_ROTATION, 90);\n// 配置视频与显示屏匹配模式（缩放与显示窗口适配，裁剪与显示窗口适配）\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_SCALING_MODE, SCALING_MODE_SCALE_CROP);\nint32_t ret = OH_VideoDecoder_SetParameter(videoDec, format);\nOH_AVFormat_Destroy(format); 调用OH_VideoDecoder_Prepare()解码器就绪。 该接口将在解码器运行前进行一些数据的准备工作。 ret = OH_VideoDecoder_Prepare(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} 调用OH_VideoDecoder_Start()启动解码器。 // 启动解码器，开始解码\nint32_t ret = OH_VideoDecoder_Start(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} （可选）调用OH_AVCencInfo_SetAVBuffer()，设置cencInfo。 若当前播放的节目是DRM加密节目，应用自行实现媒体解封装功能而非使用系统解封装功能时，需调用OH_AVCencInfo_SetAVBuffer()将cencInfo设置到AVBuffer，这样AVBuffer携带待解密的数据以及cencInfo，以实现AVBuffer中媒体数据的解密。当应用使用系统解封装功能时，则无需调用此接口。 添加头文件。 #include <multimedia/player_framework/native_cencinfo.h> 在 CMake 脚本中链接动态库。 target_link_libraries(sample PUBLIC libnative_media_avcencinfo.so) 使用示例：  buffer：回调函数OnNeedInputBuffer传入的参数。  uint32_t keyIdLen = DRM_KEY_ID_SIZE;\nuint8_t keyId[] = {\n    0xd4, 0xb2, 0x01, 0xe4, 0x61, 0xc8, 0x98, 0x96,\n    0xcf, 0x05, 0x22, 0x39, 0x8d, 0x09, 0xe6, 0x28};\nuint32_t ivLen = DRM_KEY_IV_SIZE;\nuint8_t iv[] = {\n    0xbf, 0x77, 0xed, 0x51, 0x81, 0xde, 0x36, 0x3e,\n    0x52, 0xf7, 0x20, 0x4f, 0x72, 0x14, 0xa3, 0x95};\nuint32_t encryptedBlockCount = 0;\nuint32_t skippedBlockCount = 0;\nuint32_t firstEncryptedOffset = 0;\nuint32_t subsampleCount = 1;\nDrmSubsample subsamples[1] = { {0x10, 0x16} };\n// 创建CencInfo实例\nOH_AVCencInfo *cencInfo = OH_AVCencInfo_Create();\nif (cencInfo == nullptr) {\n    // 异常处理\n}\n// 设置解密算法\nOH_AVErrCode errNo = OH_AVCencInfo_SetAlgorithm(cencInfo, DRM_ALG_CENC_AES_CTR);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 设置KeyId和Iv\nerrNo = OH_AVCencInfo_SetKeyIdAndIv(cencInfo, keyId, keyIdLen, iv, ivLen);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 设置Sample信息\nerrNo = OH_AVCencInfo_SetSubsampleInfo(cencInfo, encryptedBlockCount, skippedBlockCount, firstEncryptedOffset,\n    subsampleCount, subsamples);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 设置模式：KeyId、Iv和SubSamples已被设置\nerrNo = OH_AVCencInfo_SetMode(cencInfo, DRM_CENC_INFO_KEY_IV_SUBSAMPLES_SET);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 将CencInfo设置到AVBuffer中\nerrNo = OH_AVCencInfo_SetAVBuffer(cencInfo, buffer);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 销毁CencInfo实例\nerrNo = OH_AVCencInfo_Destroy(cencInfo);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n} 调用OH_VideoDecoder_PushInputBuffer()写入解码码流。 送入输入队列进行解码，以下示例中：  buffer：回调函数OnNeedInputBuffer传入的参数，可以通过OH_AVBuffer_GetAddr接口获取输入码流虚拟地址。 index：回调函数OnNeedInputBuffer传入的参数，与buffer唯一对应的标识。 size, offset, pts, frameData：输入尺寸、偏移量、时间戳、帧数据等字段信息，获取方式可以参考音视频解封装。 flags：缓冲区标记的类别，请参考OH_AVCodecBufferFlags。  std::shared_ptr<CodecBufferInfo> bufferInfo = inQueue.Dequeue();\nstd::shared_lock<std::shared_mutex> lock(codecMutex);\nif (bufferInfo == nullptr || !bufferInfo->isValid) {\n    // 异常处理\n}\n// 写入码流数据\nuint8_t *addr = OH_AVBuffer_GetAddr(bufferInfo->buffer);\nint32_t capcacity = OH_AVBuffer_GetCapacity(bufferInfo->buffer);\nif (size > capcacity) {\n    // 异常处理\n}\nmemcpy(addr, frameData, size);\n// 配置帧数据的输入尺寸、偏移量、时间戳等字段信息\nOH_AVCodecBufferAttr info;\ninfo.size = size;\ninfo.offset = offset;\ninfo.pts = pts;\ninfo.flags = flags;\n// info信息写入buffer\nint32_t ret = OH_AVBuffer_SetBufferAttr(bufferInfo->buffer, &info);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n// 送入解码输入队列进行解码，index为对应队列下标\nret = OH_VideoDecoder_PushInputBuffer(videoDec, bufferInfo->index);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} 调用OH_VideoDecoder_RenderOutputBuffer()/OH_VideoDecoder_RenderOutputBufferAtTime()显示并释放解码帧， 或调用OH_VideoDecoder_FreeOutputBuffer()释放解码帧。 以下示例中：  index：回调函数OnNewOutputBuffer传入的参数，与buffer唯一对应的标识。 buffer：回调函数OnNewOutputBuffer传入的参数，Surface模式调用者无法通过OH_AVBuffer_GetAddr接口获取图像虚拟地址。  std::shared_ptr<CodecBufferInfo> bufferInfo = outQueue.Dequeue();\nstd::shared_lock<std::shared_mutex> lock(codecMutex);\nif (bufferInfo == nullptr || !bufferInfo->isValid) {\n    // 异常处理\n}\n// 获取解码后信息\nOH_AVCodecBufferAttr info;\nint32_t ret = OH_AVBuffer_GetBufferAttr(bufferInfo->buffer, &info);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n// 值由调用者决定\nbool isRender;\nbool isNeedRenderAtTime;\nif (isRender) {\n    // 显示并释放已完成处理的信息，index为对应buffer队列下标\n    if (isNeedRenderAtTime){\n        // 获取系统绝对时间，renderTimestamp由调用者结合业务指定显示时间\n        int64_t renderTimestamp =\n            std::chrono::duration_cast<std::chrono::nanoseconds>(std::chrono::high_resolution_clock::now().time_since_epoch()).count();\n        ret = OH_VideoDecoder_RenderOutputBufferAtTime(videoDec, bufferInfo->index, renderTimestamp);\n    } else {\n       ret = OH_VideoDecoder_RenderOutputBuffer(videoDec, bufferInfo->index);\n    }\n\n} else {\n    // 释放已完成处理的信息\n    ret = OH_VideoDecoder_FreeOutputBuffer(videoDec, bufferInfo->index);\n}\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}     如果要获取buffer的属性，如pixel_format、stride等可通过调用OH_NativeWindow_NativeWindowHandleOpt接口获取。   （可选）调用OH_VideoDecoder_Flush()刷新解码器。 调用OH_VideoDecoder_Flush接口后，解码器仍处于运行态，但会清除解码器中缓存的输入和输出数据及参数集如H264格式的PPS/SPS。 此时需要调用OH_VideoDecoder_Start接口重新开始解码。 以下示例中：  xpsData, xpsSize：PPS/SPS信息，获取方式可以参考音视频解封装。  std::unique_lock<std::shared_mutex> lock(codecMutex);\n// 刷新解码器videoDec\nint32_t ret = OH_VideoDecoder_Flush(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\ninQueue.Flush();\noutQueue.Flush();\n// 重新开始解码\nret = OH_VideoDecoder_Start(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n\nstd::shared_ptr<CodecBufferInfo> bufferInfo = outQueue.Dequeue();\nif (bufferInfo == nullptr || !bufferInfo->isValid) {\n    // 异常处理\n}\n// 重传PPS/SPS\n// 配置帧数据PPS/SPS信息\nuint8_t *addr = OH_AVBuffer_GetAddr(bufferInfo->buffer);\nint32_t capcacity = OH_AVBuffer_GetCapacity(bufferInfo->buffer);\nif (xpsSize > capcacity) {\n    // 异常处理\n}\nmemcpy(addr, xpsData, xpsSize);\nOH_AVCodecBufferAttr info;\ninfo.flags = AVCODEC_BUFFER_FLAG_CODEC_DATA;\n// info信息写入buffer\nret = OH_AVBuffer_SetBufferAttr(bufferInfo->buffer, &info);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n// 将帧数据推送到解码器中，index为对应队列下标\nret = OH_VideoDecoder_PushInputBuffer(videoDec, bufferInfo->index);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}     Flush之后，重新调用OH_VideoDecoder_Start接口时，需要重新传PPS/SPS。   （可选）调用OH_VideoDecoder_Reset()重置解码器。 调用OH_VideoDecoder_Reset接口后，解码器回到初始化的状态，需要调用OH_VideoDecoder_Configure接口、OH_VideoDecoder_SetSurface接口和OH_VideoDecoder_Prepare接口重新配置。 std::unique_lock<std::shared_mutex> lock(codecMutex);\n// 重置解码器videoDec\nint32_t ret = OH_VideoDecoder_Reset(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\ninQueue.Flush();\noutQueue.Flush();\n// 重新配置解码器参数\nret = OH_VideoDecoder_Configure(videoDec, format);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n// Surface模式重新配置surface，而Buffer模式不需要配置surface\nret = OH_VideoDecoder_SetSurface(videoDec, window);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n// 解码器重新就绪\nret = OH_VideoDecoder_Prepare(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} （可选）调用OH_VideoDecoder_Stop()停止解码器。 调用OH_VideoDecoder_Stop()后，解码器保留了解码实例，释放输入输出buffer。调用者可以直接调用OH_VideoDecoder_Start接口继续解码，输入的第一个buffer需要携带参数集，从IDR帧开始送入。 std::unique_lock<std::shared_mutex> lock(codecMutex);\n// 终止解码器videoDec\nint32_t ret = OH_VideoDecoder_Stop(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\ninQueue.Flush();\noutQueue.Flush(); 调用OH_VideoDecoder_Destroy()销毁解码器实例，释放资源。      不能在回调函数中调用； 执行该步骤之后，需要调用者将videoDec指向NULL，防止野指针导致程序错误。    std::unique_lock<std::shared_mutex> lock(codecMutex);\n// 调用OH_VideoDecoder_Destroy，注销解码器\nint32_t ret = AV_ERR_OK;\nif (videoDec != NULL) {\n    ret = OH_VideoDecoder_Destroy(videoDec);\n    videoDec = NULL;\n}\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\ninQueue.Flush();\noutQueue.Flush(); 
[h2]Buffer模式
参考以下示例代码，调用者可以完成Buffer模式下视频解码的全流程。此处以H.264文件输入，解码成YUV文件为例。
本模块目前仅支持异步模式的数据轮转。
 添加头文件。 #include <multimedia/player_framework/native_avcodec_videodecoder.h>\n#include <multimedia/player_framework/native_avcapability.h>\n#include <multimedia/player_framework/native_avcodec_base.h>\n#include <multimedia/player_framework/native_avformat.h>\n#include <multimedia/player_framework/native_avbuffer.h>\n#include <native_buffer/native_buffer.h>\n#include <fstream> 创建解码器实例对象。 与Surface模式相同，此处不再赘述。 // 通过codecname创建解码器，应用有特殊需求，比如选择支持某种分辨率规格的解码器，可先查询capability，再根据codec name创建解码器。\nOH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, false);\nconst char *name = OH_AVCapability_GetName(capability);\nOH_AVCodec *videoDec = OH_VideoDecoder_CreateByName(name); // 通过MIME TYPE创建解码器，只能创建系统推荐的特定编解码器\n// 涉及创建多路编解码器时，优先创建硬件解码器实例，硬件资源不够时再创建软件解码器实例\n// 软/硬解: 创建H264解码器\nOH_AVCodec *videoDec = OH_VideoDecoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);\n// 硬解: 创建H265解码器\nOH_AVCodec *videoDec = OH_VideoDecoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_HEVC); 调用OH_VideoDecoder_RegisterCallback()设置回调函数。 注册回调函数指针集合OH_AVCodecCallback，包括：  OH_AVCodecOnError 解码器运行错误，返回的错误码详情请参见：OH_AVCodecOnError； OH_AVCodecOnStreamChanged 码流信息变化，如码流宽、高变化； OH_AVCodecOnNeedInputBuffer 运行过程中需要新的输入数据，即解码器已准备好，可以输入数据； OH_AVCodecOnNewOutputBuffer 运行过程中产生了新的输出数据，即解码完成。  调用者可以通过处理该回调报告的信息，确保解码器正常运转。 回调函数的具体实现可参考示例工程。 int32_t cropTop = 0;\nint32_t cropBottom = 0;\nint32_t cropLeft = 0;\nint32_t cropRight = 0;\nbool isFirstFrame = true;\n// 解码异常回调OH_AVCodecOnError实现\nstatic void OnError(OH_AVCodec *codec, int32_t errorCode, void *userData)\n{\n    // 回调的错误码由调用者判断处理\n    (void)codec;\n    (void)errorCode;\n    (void)userData;\n}\n\n// 解码数据流变化回调OH_AVCodecOnStreamChanged实现\nstatic void OnStreamChanged(OH_AVCodec *codec, OH_AVFormat *format, void *userData)\n{\n    // 可选, 调用者需要获取视频宽、高、跨距等时可配置\n    // 可通过format获取到变化后的视频宽、高、跨距等\n    (void)codec;\n    (void)userData;\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_PIC_WIDTH, &width);\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_PIC_HEIGHT, &height);\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_STRIDE, &widthStride);\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_SLICE_HEIGHT, &heightStride);\n    // 获取裁剪矩形信息可选\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_TOP, &cropTop);\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_BOTTOM, &cropBottom);\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_LEFT, &cropLeft);\n    OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_RIGHT, &cropRight);\n}\n\n// 解码输入回调OH_AVCodecOnNeedInputBuffer实现\nstatic void OnNeedInputBuffer(OH_AVCodec *codec, uint32_t index, OH_AVBuffer *buffer, void *userData)\n{\n    // 输入帧的数据buffer和对应的index送入inQueue队列\n    (void)codec;\n    (void)userData;\n    inQueue.Enqueue(std::make_shared<CodecBufferInfo>(index, buffer));\n}\n\n// 解码输出回调OH_AVCodecOnNewOutputBuffer实现\nstatic void OnNewOutputBuffer(OH_AVCodec *codec, uint32_t index, OH_AVBuffer *buffer, void *userData)\n{\n    // 可选, 调用者需要获取视频宽、高、跨距等时可配置\n    // 获取视频宽、高、跨距\n    if (isFirstFrame) {\n        OH_AVFormat *format = OH_VideoDecoder_GetOutputDescription(codec);\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_PIC_WIDTH, &width);\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_PIC_HEIGHT, &height);\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_STRIDE, &widthStride);\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_SLICE_HEIGHT, &heightStride);\n        // 获取裁剪矩形信息可选\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_TOP, &cropTop);\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_BOTTOM, &cropBottom);\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_LEFT, &cropLeft);\n        OH_AVFormat_GetIntValue(format, OH_MD_KEY_VIDEO_CROP_RIGHT, &cropRight);\n        OH_AVFormat_Destroy(format);\n        isFirstFrame = false;\n    }\n    // 完成帧的数据buffer和对应的index送入outQueue队列\n    (void)userData;\n    outQueue.Enqueue(std::make_shared<CodecBufferInfo>(index, buffer));\n}\n// 配置异步回调，调用OH_VideoDecoder_RegisterCallback接口\nOH_AVCodecCallback cb = {&OnError, &OnStreamChanged, &OnNeedInputBuffer, &OnNewOutputBuffer};\n// 配置异步回调\nint32_t ret = OH_VideoDecoder_RegisterCallback(videoDec, cb, NULL); // NULL:用户特定数据userData为空 \nif (ret != AV_ERR_OK) {\n    // 异常处理\n}     在回调函数中，对数据队列进行操作时，需要注意多线程同步的问题。   （可选）OH_VideoDecoder_SetDecryptionConfig设置解密配置。在获取到DRM信息(参考音视频解封装开发步骤第4步)，完成DRM许可证申请后，通过此接口进行解密配置。此接口需在Prepare前调用。在Buffer模式下，DRM解密能力仅支持非安全视频通路。DRM相关接口详见DRM API文档。 添加头文件。 #include <multimedia/drm_framework/native_mediakeysystem.h>\n#include <multimedia/drm_framework/native_mediakeysession.h>\n#include <multimedia/drm_framework/native_drm_err.h>\n#include <multimedia/drm_framework/native_drm_common.h> 在 CMake 脚本中链接动态库。 target_link_libraries(sample PUBLIC libnative_drm.so) 使用示例： // 根据DRM信息创建指定的DRM系统, 以创建\"com.wiseplay.drm\"为例\nMediaKeySystem *system = nullptr;\nint32_t ret = OH_MediaKeySystem_Create(\"com.wiseplay.drm\", &system);\nif (system == nullptr) {\n    printf(\"create media key system failed\");\n    return;\n}\n\n// 创建解密会话\n// 使用非安全视频通路，应创建CONTENT_PROTECTION_LEVEL_SW_CRYPTO及以上内容保护级别的MediaKeySession\nMediaKeySession *session = nullptr;\nDRM_ContentProtectionLevel contentProtectionLevel = CONTENT_PROTECTION_LEVEL_SW_CRYPTO;\nret = OH_MediaKeySystem_CreateMediaKeySession(system, &contentProtectionLevel, &session);\nif (ret != DRM_OK) {\n    // 如创建失败，请查看DRM接口文档及日志信息\n    printf(\"create media key session failed.\");\n    return;\n}\nif (session == nullptr) {\n    printf(\"media key session is nullptr.\");\n    return;\n}\n// 获取许可证请求、设置许可证响应等\n// 设置解密配置, 即将解密会话、安全视频通路标志设置到解码器中。\nbool secureVideoPath = false;\nret = OH_VideoDecoder_SetDecryptionConfig(videoDec, session, secureVideoPath); 调用OH_VideoDecoder_Configure()配置解码器。 与Surface模式相同，此处不再赘述。 OH_AVFormat *format = OH_AVFormat_Create();\n// 写入format\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_WIDTH, width); // 必须配置\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_HEIGHT, height); // 必须配置\nOH_AVFormat_SetIntValue(format, OH_MD_KEY_PIXEL_FORMAT, pixelFormat);\n// 配置解码器\nint32_t ret = OH_VideoDecoder_Configure(videoDec, format);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\nOH_AVFormat_Destroy(format); 调用OH_VideoDecoder_Prepare()解码器就绪。 该接口将在解码器运行前进行一些数据的准备工作。 int32_t ret = OH_VideoDecoder_Prepare(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} 调用OH_VideoDecoder_Start()启动解码器。 std::unique_ptr<std::ofstream> outputFile = std::make_unique<std::ofstream>();\noutputFile->open(\"/*yourpath*.yuv\", std::ios::out | std::ios::binary | std::ios::ate);\n// 启动解码器，开始解码\nint32_t ret = OH_VideoDecoder_Start(videoDec);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} （可选）调用OH_AVCencInfo_SetAVBuffer()，设置cencInfo。 与Surface模式相同，此处不再赘述。 使用示例： uint32_t keyIdLen = DRM_KEY_ID_SIZE;\nuint8_t keyId[] = {\n    0xd4, 0xb2, 0x01, 0xe4, 0x61, 0xc8, 0x98, 0x96,\n    0xcf, 0x05, 0x22, 0x39, 0x8d, 0x09, 0xe6, 0x28};\nuint32_t ivLen = DRM_KEY_IV_SIZE;\nuint8_t iv[] = {\n    0xbf, 0x77, 0xed, 0x51, 0x81, 0xde, 0x36, 0x3e,\n    0x52, 0xf7, 0x20, 0x4f, 0x72, 0x14, 0xa3, 0x95};\nuint32_t encryptedBlockCount = 0;\nuint32_t skippedBlockCount = 0;\nuint32_t firstEncryptedOffset = 0;\nuint32_t subsampleCount = 1;\nDrmSubsample subsamples[1] = { {0x10, 0x16} };\n// 创建CencInfo实例\nOH_AVCencInfo *cencInfo = OH_AVCencInfo_Create();\nif (cencInfo == nullptr) {\n    // 异常处理\n}\n// 设置解密算法\nOH_AVErrCode errNo = OH_AVCencInfo_SetAlgorithm(cencInfo, DRM_ALG_CENC_AES_CTR);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 设置KeyId和Iv\nerrNo = OH_AVCencInfo_SetKeyIdAndIv(cencInfo, keyId, keyIdLen, iv, ivLen);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 设置Sample信息\nerrNo = OH_AVCencInfo_SetSubsampleInfo(cencInfo, encryptedBlockCount, skippedBlockCount, firstEncryptedOffset,\n    subsampleCount, subsamples);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 设置模式：KeyId、Iv和SubSamples已被设置\nerrNo = OH_AVCencInfo_SetMode(cencInfo, DRM_CENC_INFO_KEY_IV_SUBSAMPLES_SET);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 将CencInfo设置到AVBuffer中\nerrNo = OH_AVCencInfo_SetAVBuffer(cencInfo, buffer);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n}\n// 销毁CencInfo实例\nerrNo = OH_AVCencInfo_Destroy(cencInfo);\nif (errNo != AV_ERR_OK) {\n    // 异常处理\n} 调用OH_VideoDecoder_PushInputBuffer()写入解码码流。 与Surface模式相同，此处不再赘述。 std::shared_ptr<CodecBufferInfo> bufferInfo = inQueue.Dequeue();\nstd::shared_lock<std::shared_mutex> lock(codecMutex);\nif (bufferInfo == nullptr || !bufferInfo->isValid) {\n    // 异常处理\n}\n// 写入码流数据\nuint8_t *addr = OH_AVBuffer_GetAddr(bufferInfo->buffer);\nint32_t capcacity = OH_AVBuffer_GetCapacity(bufferInfo->buffer);\nif (size > capcacity) {\n    // 异常处理\n}\nmemcpy(addr, frameData, size);\n// 配置帧数据的输入尺寸、偏移量、时间戳等字段信息\nOH_AVCodecBufferAttr info;\ninfo.size = size;\ninfo.offset = offset;\ninfo.pts = pts;\ninfo.flags = flags;\n// info信息写入buffer\nret = OH_AVBuffer_SetBufferAttr(bufferInfo->buffer, &info);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n// 送入解码输入队列进行解码，index为对应队列下标\nint32_t ret = OH_VideoDecoder_PushInputBuffer(videoDec, bufferInfo->index);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} 调用OH_VideoDecoder_FreeOutputBuffer()释放解码帧。 以下示例中：  index：回调函数OnNewOutputBuffer传入的参数，与buffer唯一对应的标识。 buffer： 回调函数OnNewOutputBuffer传入的参数，可以通过OH_AVBuffer_GetAddr接口获取图像虚拟地址。  std::shared_ptr<CodecBufferInfo> bufferInfo = outQueue.Dequeue();\nstd::shared_lock<std::shared_mutex> lock(codecMutex);\nif (bufferInfo == nullptr || !bufferInfo->isValid) {\n    // 异常处理\n}\n// 获取解码后信息\nOH_AVCodecBufferAttr info;\nint32_t ret = OH_AVBuffer_GetBufferAttr(bufferInfo->buffer, &info);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n}\n// 将解码完成数据data写入到对应输出文件中\noutputFile->write(reinterpret_cast<char *>(OH_AVBuffer_GetAddr(bufferInfo->buffer)), info.size);\n// Buffer模式，释放已完成写入的数据，index为对应buffer队列下标\nret = OH_VideoDecoder_FreeOutputBuffer(videoDec, bufferInfo->index);\nif (ret != AV_ERR_OK) {\n    // 异常处理\n} NV12/NV21图像如果需要依次将Y,U,V三个分量拷贝至另一块buffer中，以NV12图像为例，按行拷贝示例如下： 以NV12图像为例，width、height、wStride、hStride图像排布参考下图：  OH_MD_KEY_VIDEO_PIC_WIDTH表示width； OH_MD_KEY_VIDEO_PIC_HEIGHT表示height； OH_MD_KEY_VIDEO_STRIDE表示wStride； OH_MD_KEY_VIDEO_SLICE_HEIGHT表示hStride。   添加头文件。 #include <string.h> 使用示例： // 源内存区域的宽、高，通过回调函数OnStreamChanged或接口OH_VideoDecoder_GetOutputDescription获取\nstruct Rect\n{\n    int32_t width;\n    int32_t height;\n};\n\nstruct DstRect // 目标内存区域的宽、高跨距，由调用者自行设置\n{\n    int32_t wStride;\n    int32_t hStride;\n};\n// 源内存区域的宽、高跨距，通过回调函数OnStreamChanged或接口OH_VideoDecoder_GetOutputDescription获取\nstruct SrcRect\n{\n    int32_t wStride;\n    int32_t hStride;\n};\n\nRect rect = {320, 240};\nDstRect dstRect = {320, 240};\nSrcRect srcRect = {320, 256};\nuint8_t* dst = new uint8_t[dstRect.hStride * dstRect.wStride * 3 / 2]; // 目标内存区域的指针\nuint8_t* src = new uint8_t[srcRect.hStride * srcRect.wStride * 3 / 2]; // 源内存区域的指针\nuint8_t* dstTemp = dst;\nuint8_t* srcTemp = src;\n\n\n// Y 将Y区域的源数据复制到另一个区域的目标数据中\nfor (int32_t i = 0; i < rect.height; ++i) {\n    //将源数据的一行数据复制到目标数据的一行中\n    memcpy_s(dstTemp, srcTemp, rect.width);\n    // 更新源数据和目标数据的指针，进行下一行的复制。每更新一次源数据和目标数据的指针都向下移动一个wStride\n    dstTemp += dstRect.wStride;\n    srcTemp += srcRect.wStride;\n}\n// padding\n// 更新源数据和目标数据的指针，指针都向下移动一个padding\ndstTemp += (dstRect.hStride - rect.height) * dstRect.wStride;\nsrcTemp += (srcRect.hStride - rect.height) * srcRect.wStride;\nrect.height >>= 1;\n// UV 将UV区域的源数据复制到另一个区域的目标数据中\nfor (int32_t i = 0; i < rect.height; ++i) {\n    memcpy_s(dstTemp, srcTemp, rect.width);\n    dstTemp += dstRect.wStride;\n    srcTemp += srcRect.wStride;\n}\n\ndelete[] dst;\ndst = nullptr;\ndelete[] src;\nsrc = nullptr; 硬件解码在处理buffer数据时（释放数据前），输出回调调用者收到的AVbuffer是宽高对齐后的图像数据。 一般需要获取数据的宽高、跨距、像素格式来保证解码输出数据被正确的处理。 具体实现请参考：Buffer模式的步骤3-调用OH_VideoDecoder_RegisterCallback()设置回调函数来获取数据的宽高、跨距、像素格式。 
后续流程（包括刷新解码器、重置解码器、停止解码器、销毁解码器）与Surface模式基本一致，请参考Surface模式的步骤13-16。
