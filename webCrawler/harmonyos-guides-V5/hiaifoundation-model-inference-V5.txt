模型推理
基本概念
该场景是基本模型的使用场景，主要包含模型的编译和推理，其他场景是基础场景的一个扩展和功能增强。
业务流程
模型推理的主要开发流程如下图所示：
接口说明
以下接口为主要流程接口，如要使用更丰富的编译、加载和执行时的配置，请参见API参考。
接口名
描述
OH_NNCompilation* OH_NNCompilation_ConstructWithOfflineModelBuffer(const void *modelBuffer, size_t modelSize);
根据模型buffer创建模型编译实例。
OH_NN_ReturnCode OH_NNCompilation_SetDevice(OH_NNCompilation *compilation, size_t deviceID);
设置模型编译和执行的目标设备。
OH_NN_ReturnCode OH_NNCompilation_Build(OH_NNCompilation *compilation);
执行模型编译，生成编译后的模型保存在compilation中。
OH_NNExecutor* OH_NNExecutor_Construct(OH_NNCompilation *compilation);
根据编译后的模型，创建模型推理的执行器。
NN_Tensor* OH_NNTensor_Create(size_t deviceID, NN_TensorDesc* tensorDesc);
构造输入输出Tensor。
OH_NN_ReturnCode OH_NNExecutor_RunSync(OH_NNExecutor *executor, NN_Tensor *inputTensor[], size_t inputCount, NN_Tensor *outputTensor[], size_t outputCount);
执行模型的同步推理。
void OH_NNCompilation_Destroy(OH_NNCompilation **compilation);
销毁模型编译实例。
OH_NN_ReturnCode OH_NNTensor_Destroy(NN_Tensor** tensor);
销毁输入输出Tensor。
void OH_NNExecutor_Destroy(OH_NNExecutor **executor);
销毁模型推理的执行器。
开发步骤
以下为模型推理的主要开发步骤，具体实现请参见SampleCode。
准备模型和开发环境。准备om模型，可以通过tools_omg工具生成或从Model Zoo获取。下载并配置DevEco Studio IDE环境，确保可以正常开发和调试HarmonyOS应用。 
创建DevEco Studio项目。
创建模型编译实例。调用OH_NNCompilation_ConstructWithOfflineModelBuffer读取模型buffer，创建模型编译实例。或者通过调用OH_NNCompilation_ConstructWithOfflineModelFile直接读取模型文件，创建模型编译实例。 选择目标device：HiAIFoundation。调用OH_NNDevice_GetAllDevicesID，获取所有的设备ID，查找name为\"HIAI_F\"字段的设备ID，记录并通过OH_NNCompilation_SetDevice设置到步骤3创建的编译实例中。 
执行模型编译。调用OH_NNCompilation_Build，传入步骤3创建的模型编译实例，即可执行模型编译，编译后的模型数据仍然保存在模型编译实例中。 
创建模型执行器。调用OH_NNExecutor_Construct，创建编译后模型对应的执行器实例。执行器创建完成后即可调用OH_NNCompilation_Destroy销毁模型编译实例。 
构造输入输出Tensor。调用OH_NNExecutor_GetInputCount，查询输入的个数，通过OH_NNExecutor_CreateInputTensorDesc获取到对应索引的TensorDesc，根据该TensorDesc通过OH_NNTensor_Create创建Tensor，即可向Tensor中写入实际数据。输出Tensor的构造与输入Tensor的构造过程一致。 
执行模型推理。调用OH_NNExecutor_RunSync，执行模型的同步推理功能，模型的输出数据保存在outputTensors中。开发者可根据需要对输出数据做相应的处理以得到期望的内容。 
销毁实例。调用OH_NNExecutor_Destroy，销毁创建的模型执行器实例。调用OH_NNTensor_Destroy，销毁创建的输入输出Tensor。 
