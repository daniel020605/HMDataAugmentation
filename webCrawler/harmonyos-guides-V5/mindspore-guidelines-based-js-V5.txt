使用MindSpore Lite实现图像分类（ArkTS）
场景说明
开发者可以使用@ohos.ai.mindSporeLite，在UI代码中集成MindSpore Lite能力，快速部署AI算法，进行AI模型推理，实现图像分类的应用。
图像分类可实现对图像中物体的识别，在医学影像分析、自动驾驶、电子商务、人脸识别等有广泛的应用。
基本概念
在进行开发前，请先了解以下概念。
张量：它与数组和矩阵非常相似，是MindSpore Lite网络运算中的基本数据结构。
Float16推理模式： Float16又称半精度，它使用16比特表示一个数。Float16推理模式表示推理的时候用半精度进行推理。
接口说明
这里给出MindSpore Lite推理的通用开发流程中涉及的一些接口，具体请见下列表格。更多接口及详细内容，请见@ohos.ai.mindSporeLite (推理能力)。
开发流程
 选择图像分类模型。 在端侧使用MindSpore Lite推理模型，实现对选择的图片进行分类。 
环境准备
安装DevEco Studio，要求版本 >= 4.1，并更新SDK到API 11或以上。
开发步骤
本文以对相册的一张图片进行推理为例，提供使用MindSpore Lite实现图像分类的开发指导。
[h2]选择模型
本示例程序中使用的图像分类模型文件为mobilenetv2.ms，放置在entry/src/main/resources/rawfile工程目录下。
如果开发者有其他图像分类的预训练模型，请参考MindSpore Lite 模型转换介绍，将原始模型转换成.ms格式。
[h2]编写代码
图像输入和预处理
 此处以获取相册图片为例，调用@ohos.file.picker 实现相册图片文件的选择。 import { photoAccessHelper } from '@kit.MediaLibraryKit';\nimport { BusinessError } from '@kit.BasicServicesKit';\n\nlet uris: Array<string> = [];\n\n// 创建图片文件选择实例\nlet photoSelectOptions = new photoAccessHelper.PhotoSelectOptions();\n\n// 设置选择媒体文件类型为IMAGE，设置选择媒体文件的最大数目\nphotoSelectOptions.MIMEType = photoAccessHelper.PhotoViewMIMETypes.IMAGE_TYPE;\nphotoSelectOptions.maxSelectNumber = 1;\n\n// 创建图库选择器实例，调用select()接口拉起图库界面进行文件选择。文件选择成功后，返回photoSelectResult结果集。\nlet photoPicker = new photoAccessHelper.PhotoViewPicker();\nphotoPicker.select(photoSelectOptions, async (\n  err: BusinessError, photoSelectResult: photoAccessHelper.PhotoSelectResult) => {\n  if (err) {\n    console.error('MS_LITE_ERR: PhotoViewPicker.select failed with err: ' + JSON.stringify(err));\n    return;\n  }\n  console.info('MS_LITE_LOG: PhotoViewPicker.select successfully, ' +\n    'photoSelectResult uri: ' + JSON.stringify(photoSelectResult));\n  uris = photoSelectResult.photoUris;\n  console.info('MS_LITE_LOG: uri: ' + uris);\n}) 根据模型的输入尺寸，调用@ohos.multimedia.image （实现图片处理）、@ohos.file.fs （实现基础文件操作） API对选择图片进行裁剪、获取图片buffer数据，并进行标准化处理。 import { image } from '@kit.ImageKit';\nimport { fileIo } from '@kit.CoreFileKit';\n\nlet modelInputHeight: number = 224;\nlet modelInputWidth: number = 224;\n\n// 使用fileIo.openSync接口，通过uri打开这个文件得到fd\nlet file = fileIo.openSync(this.uris[0], fileIo.OpenMode.READ_ONLY);\nconsole.info('MS_LITE_LOG: file fd: ' + file.fd);\n\n// 通过fd使用fileIo.readSync接口读取这个文件内的数据\nlet inputBuffer = new ArrayBuffer(4096000);\nlet readLen = fileIo.readSync(file.fd, inputBuffer);\nconsole.info('MS_LITE_LOG: readSync data to file succeed and inputBuffer size is:' + readLen);\n\n// 通过PixelMap预处理\nlet imageSource = image.createImageSource(file.fd);\nimageSource.createPixelMap().then((pixelMap) => {\n  pixelMap.getImageInfo().then((info) => {\n    console.info('MS_LITE_LOG: info.width = ' + info.size.width);\n    console.info('MS_LITE_LOG: info.height = ' + info.size.height);\n    // 根据模型输入的尺寸，将图片裁剪为对应的size，获取图片buffer数据readBuffer\n    pixelMap.scale(256.0 / info.size.width, 256.0 / info.size.height).then(() => {\n      pixelMap.crop(\n        { x: 16, y: 16, size: { height: modelInputHeight, width: modelInputWidth } }\n      ).then(async () => {\n        let info = await pixelMap.getImageInfo();\n        console.info('MS_LITE_LOG: crop info.width = ' + info.size.width);\n        console.info('MS_LITE_LOG: crop info.height = ' + info.size.height);\n        // 需要创建的像素buffer大小\n        let readBuffer = new ArrayBuffer(modelInputHeight * modelInputWidth * 4);\n        await pixelMap.readPixelsToBuffer(readBuffer);\n        console.info('MS_LITE_LOG: Succeeded in reading image pixel data, buffer: ' +\n        readBuffer.byteLength);\n        // 处理readBuffer，转换成float32格式，并进行标准化处理\n        const imageArr = new Uint8Array(\n          readBuffer.slice(0, modelInputHeight * modelInputWidth * 4));\n        console.info('MS_LITE_LOG: imageArr length: ' + imageArr.length);\n        let means = [0.485, 0.456, 0.406];\n        let stds = [0.229, 0.224, 0.225];\n        let float32View = new Float32Array(modelInputHeight * modelInputWidth * 3);\n        let index = 0;\n        for (let i = 0; i < imageArr.length; i++) {\n          if ((i + 1) % 4 == 0) {\n            float32View[index] = (imageArr[i - 3] / 255.0 - means[0]) / stds[0]; // B\n            float32View[index+1] = (imageArr[i - 2] / 255.0 - means[1]) / stds[1]; // G\n            float32View[index+2] = (imageArr[i - 1] / 255.0 - means[2]) / stds[2]; // R\n            index += 3;\n          }\n        }\n        console.info('MS_LITE_LOG: float32View length: ' + float32View.length);\n        let printStr = 'float32View data:';\n        for (let i = 0; i < 20; i++) {\n          printStr += ' ' + float32View[i];\n        }\n        console.info('MS_LITE_LOG: float32View data: ' + printStr);\n      })\n    })\n  });\n}); 
编写推理代码
 工程默认设备定义的能力集可能不包含MindSporeLite。需在DevEco Studio工程的entry/src/main目录下，手动创建syscap.json文件，内容如下： {\n  \"devices\": {\n    \"general\": [\n      // 需跟module.json5中deviceTypes保持一致。\n      \"default\"\n    ]\n  },\n  \"development\": {\n    \"addedSysCaps\": [\n      \"SystemCapability.AI.MindSporeLite\"\n    ]\n  }\n} 调用@ohos.ai.mindSporeLite实现端侧推理。具体开发过程及细节如下：  创建上下文，设置线程数、设备类型等参数。 加载模型。本文从内存加载模型。 加载数据。模型执行之前需要先获取输入，再向输入的张量中填充数据。 执行推理。使用predict接口进行模型推理。  // model.ets\nimport { mindSporeLite } from '@kit.MindSporeLiteKit'\n\nexport default async function modelPredict(\n  modelBuffer: ArrayBuffer, inputsBuffer: ArrayBuffer[]): Promise<mindSporeLite.MSTensor[]> {\n\n  // 1.创建上下文，设置线程数、设备类型等参数。\n  let context: mindSporeLite.Context = {};\n  context.target = ['cpu'];\n  context.cpu = {}\n  context.cpu.threadNum = 2;\n  context.cpu.threadAffinityMode = 1;\n  context.cpu.precisionMode = 'enforce_fp32';\n\n  // 2.从内存加载模型。\n  let msLiteModel: mindSporeLite.Model = await mindSporeLite.loadModelFromBuffer(modelBuffer, context);\n\n  // 3.设置输入数据。\n  let modelInputs: mindSporeLite.MSTensor[] = msLiteModel.getInputs();\n  for (let i = 0; i < inputsBuffer.length; i++) {\n    let inputBuffer = inputsBuffer[i];\n    if (inputBuffer != null) {\n      modelInputs[i].setData(inputBuffer as ArrayBuffer);\n    }\n  }\n\n  // 4.执行推理。\n  console.info('=========MS_LITE_LOG: MS_LITE predict start=====');\n  let modelOutputs: mindSporeLite.MSTensor[] = await msLiteModel.predict(modelInputs);\n  return modelOutputs;\n} 
进行推理并输出结果
加载模型文件，调用推理函数，对相册选择的图片进行推理，并对推理结果进行处理。
import modelPredict from './model';\nimport { resourceManager } from '@kit.LocalizationKit'\n\nlet modelName: string = 'mobilenetv2.ms';\nlet max: number = 0;\nlet maxIndex: number = 0;\nlet maxArray: Array<number> = [];\nlet maxIndexArray: Array<number> = [];\n\n// 完成图像输入和预处理后的buffer数据保存在float32View，具体可见上文图像输入和预处理中float32View的定义和处理。\nlet inputs: ArrayBuffer[] = [float32View.buffer];\nlet resMgr: resourceManager.ResourceManager = getContext().getApplicationContext().resourceManager;\nresMgr.getRawFileContent(modelName).then(modelBuffer => {\n  // predict\n  modelPredict(modelBuffer.buffer.slice(0), inputs).then(outputs => {\n    console.info('=========MS_LITE_LOG: MS_LITE predict success=====');\n    // 结果打印\n    for (let i = 0; i < outputs.length; i++) {\n      let out = new Float32Array(outputs[i].getData());\n      let printStr = outputs[i].name + ':';\n      for (let j = 0; j < out.length; j++) {\n        printStr += out[j].toString() + ',';\n      }\n      console.info('MS_LITE_LOG: ' + printStr);\n      // 取分类占比的最大值\n      this.max = 0;\n      this.maxIndex = 0;\n      this.maxArray = [];\n      this.maxIndexArray = [];\n      let newArray = out.filter(value => value !== max)\n      for (let n = 0; n < 5; n++) {\n        max = out[0];\n        maxIndex = 0;\n        for (let m = 0; m < newArray.length; m++) {\n          if (newArray[m] > max) {\n            max = newArray[m];\n            maxIndex = m;\n          }\n        }\n        maxArray.push(Math.round(max * 10000))\n        maxIndexArray.push(maxIndex)\n        // filter函数，数组过滤函数\n        newArray = newArray.filter(value => value !== max)\n      }\n      console.info('MS_LITE_LOG: max:' + maxArray);\n      console.info('MS_LITE_LOG: maxIndex:' + maxIndexArray);\n    }\n    console.info('=========MS_LITE_LOG END=========');\n  })\n})
[h2]调测验证
 在DevEco Studio中连接设备，点击Run entry，编译Hap，有如下显示： Launching com.samples.mindsporelitearktsdemo\n$ hdc shell aa force-stop com.samples.mindsporelitearktsdemo\n$ hdc shell mkdir data/local/tmp/xxx\n$ hdc file send C:\\Users\\xxx\\MindSporeLiteArkTSDemo\\entry\\build\\default\\outputs\\default\\entry-default-signed.hap \"data/local/tmp/xxx\" \n$ hdc shell bm install -p data/local/tmp/xxx\n$ hdc shell rm -rf data/local/tmp/xxx\n$ hdc shell aa start -a EntryAbility -b com.samples.mindsporelitearktsdemo 在设备屏幕点击photo按钮，选择图片，点击确定。设备屏幕显示所选图片的分类结果，在日志打印结果中，过滤关键字”MS_LITE“，可得到如下结果： 08-06 03:24:33.743   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: PhotoViewPicker.select successfully, photoSelectResult uri: {\"photoUris\":[\"file://media/Photo/13/IMG_1501955351_012/plant.jpg\"]}\n08-06 03:24:33.795   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: readSync data to file succeed and inputBuffer size is:32824\n08-06 03:24:34.147   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: crop info.width = 224\n08-06 03:24:34.147   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: crop info.height = 224\n08-06 03:24:34.160   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: Succeeded in reading image pixel data, buffer: 200704\n08-06 03:24:34.970   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     =========MS_LITE_LOG: MS_LITE predict start=====\n08-06 03:24:35.432   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     =========MS_LITE_LOG: MS_LITE predict success=====\n08-06 03:24:35.447   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: Default/head-MobileNetV2Head/Sigmoid-op466:0.0000034338463592575863,0.000014028532859811094,9.119685273617506e-7,0.000049100715841632336,9.502661555416125e-7,3.945370394831116e-7,0.04346757382154465,0.00003971960904891603...\n08-06 03:24:35.499   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: max:9497,7756,1970,435,46\n08-06 03:24:35.499   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     MS_LITE_LOG: maxIndex:323,46,13,6,349\n08-06 03:24:35.499   22547-22547  A03d00/JSAPP                   com.sampl...liteark+  I     =========MS_LITE_LOG END========= 
[h2]效果示意
在设备上，点击photo按钮，选择相册中的一张图片，点击确定。在图片下方显示此图片占比前4的分类信息。
示例代码
 基于MindSporeLite接口实现图像分类 
